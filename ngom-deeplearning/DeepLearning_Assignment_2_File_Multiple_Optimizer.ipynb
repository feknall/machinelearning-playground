{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/feknall/machinelearning-playground/blob/main/DeepLearning_Assignment_2_File_Multiple_Optimizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lawYx0ID-V3"
      },
      "source": [
        "### Installation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "XdaLy_Bnpl_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install tensorflow --upgrade"
      ],
      "metadata": {
        "id": "30W9CHDAlbwJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ci1V12SED_AI"
      },
      "outputs": [],
      "source": [
        "! pip install keras-tuner --upgrade"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Keras"
      ],
      "metadata": {
        "id": "wfKOBKThjOXa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape((x_train.shape[0], -1)).astype('float32') / 255\n",
        "x_test = x_test.reshape((x_test.shape[0], -1)).astype('float32') / 255\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(x_train)\n",
        "x_train = scaler.transform(x_train)\n",
        "x_test = scaler.transform(x_test)"
      ],
      "metadata": {
        "id": "hK1KEzVGjQzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "one_hot_encoder = OneHotEncoder()\n",
        "one_hot_encoder.fit(y_train.reshape(-1, 1))\n",
        "y_train_one_hot_encoded = one_hot_encoder.transform(y_train.reshape(-1, 1)).toarray()"
      ],
      "metadata": {
        "id": "LlN_46y7jlKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "experiment_train_size = 60000\n",
        "X = x_train[:experiment_train_size]\n",
        "Y = y_train_one_hot_encoded[:experiment_train_size]"
      ],
      "metadata": {
        "id": "k2luEiczs5VA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "id": "zwYOj8hJmbLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_one_hot_encoded.shape"
      ],
      "metadata": {
        "id": "kkYs0SChmcyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "id": "v8dKUB6Umpyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXEqNMh8AkOP"
      },
      "source": [
        "### Keras Adam"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
        "import tensorflow as tf\n",
        "\n",
        "def plot_tensorflow_log(path):\n",
        "\n",
        "    # Loading too much data is slow...\n",
        "    tf_size_guidance = {\n",
        "        # 'compressedHistograms': 100,\n",
        "        # 'images': 0,\n",
        "        # 'scalars': 10000,\n",
        "        # 'histograms': 1000\n",
        "        'tensors': 200\n",
        "    }\n",
        "\n",
        "    event_acc = EventAccumulator(path, tf_size_guidance)\n",
        "    event_acc.Reload()\n",
        "\n",
        "    print(event_acc.Tags())\n",
        "\n",
        "    training_accuracies = event_acc.Tensors('epoch_accuracy')\n",
        "    tensor_np = tf.make_ndarray(training_accuracies[-1].tensor_proto)\n",
        "\n",
        "    # print(tensor_np)\n",
        "\n",
        "    y = list()\n",
        "    x = list()\n",
        "    for i in range(len(training_accuracies)):\n",
        "        y.append(tf.make_ndarray(training_accuracies[i].tensor_proto))\n",
        "        x.append(i)\n",
        "\n",
        "    return x, y"
      ],
      "metadata": {
        "id": "WjAsZl1tqSju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_file = \"/content/drive/MyDrive/deep-learning/sgd/learning_rate_project/callback/0000/execution0/train/events.out.tfevents.1648605315.f2bd2e92bee4.73.1.v2\"\n",
        "x, y = plot_tensorflow_log(log_file)"
      ],
      "metadata": {
        "id": "k52qas9FBN2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimizer"
      ],
      "metadata": {
        "id": "jXXFq8WdwSxt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "def build_model(hp):\n",
        "  optimizer = hp.Choice(\"optimizer\", [\"sgd\", \"rmsprop\", \"adam\", \"adadelta\"])\n",
        "  if optimizer == \"sgd\":\n",
        "    optimizer = keras.optimizers.SGD(learning_rate=0.001)\n",
        "  elif optimizer == \"rmsprop\":\n",
        "    optimizer = keras.optimizers.RMSprop(learning_rate=0.001)\n",
        "  elif optimizer == \"adam\":\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
        "  elif optimizer == \"adadelta\":\n",
        "    optimizer = keras.optimizers.Adadelta(learning_rate=0.001)\n",
        "\n",
        "  model = keras.Sequential()\n",
        "  model.add(Dense(10, kernel_initializer='uniform', input_shape=(784,), activation='softmax'))\n",
        "\n",
        "  model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "  return model"
      ],
      "metadata": {
        "id": "d7YCvgA_gaJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_tuner as kt\n",
        "from tensorflow import keras\n",
        "\n",
        "tuner = kt.RandomSearch(\n",
        "    hypermodel=build_model,\n",
        "    objective=\"val_accuracy\",\n",
        "    max_trials=1000,\n",
        "    executions_per_trial=1,\n",
        "    overwrite=True,\n",
        "    directory=\"/content/drive/MyDrive/deep-learning/optimizer/\",\n",
        "    project_name=\"optimizer_project\"\n",
        ")\n",
        "\n",
        "tuner.search(X, \n",
        "             Y, \n",
        "             epochs=100, \n",
        "             validation_split=0.2, \n",
        "             callbacks=[tf.keras.callbacks.TensorBoard(\"/content/drive/MyDrive/deep-learning/optimizer/optimizer_project/callback\")],\n",
        "          \n",
        ")"
      ],
      "metadata": {
        "id": "uAa_kYTMhexG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! rm -rf /content/drive/MyDrive/deep-learning/optimizer"
      ],
      "metadata": {
        "id": "SvPcd3Jepc9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "40kGyv78CDYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir /content/drive/MyDrive/deep-learning/optimizer/optimizer_project/callback"
      ],
      "metadata": {
        "id": "ENAMzPbdpeYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "log_file = \"/content/drive/MyDrive/deep-learning/sgd/learning_rate_project/callback/0000/execution0/train/events.out.tfevents.1648605315.f2bd2e92bee4.73.1.v2\"\n",
        "x, y = plot_tensorflow_log(log_file)\n",
        "plt.plot(x, y, label='0.1 learning rate - train')\n",
        "\n",
        "log_file = \"/content/drive/MyDrive/deep-learning/sgd/learning_rate_project/callback/0003/execution0/train/events.out.tfevents.1648605432.f2bd2e92bee4.73.10.v2\"\n",
        "x, y = plot_tensorflow_log(log_file)\n",
        "plt.plot(x, y, label='0.01 learning rate - train')\n",
        "\n",
        "log_file = \"/content/drive/MyDrive/deep-learning/sgd/learning_rate_project/callback/0001/execution0/train/events.out.tfevents.1648605356.f2bd2e92bee4.73.4.v2\"\n",
        "x, y = plot_tensorflow_log(log_file)\n",
        "plt.plot(x, y, label='0.001 learning rate - train')\n",
        "\n",
        "log_file = \"/content/drive/MyDrive/deep-learning/sgd/learning_rate_project/callback/0002/execution0/train/events.out.tfevents.1648605395.f2bd2e92bee4.73.7.v2\"\n",
        "x, y = plot_tensorflow_log(log_file)\n",
        "plt.plot(x, y, label='0.0001 learning rate - train')\n",
        "\n",
        "\n",
        "log_file = \"/content/drive/MyDrive/deep-learning/sgd/learning_rate_project/callback/0000/execution0/validation/events.out.tfevents.1648605318.f2bd2e92bee4.73.2.v2\"\n",
        "x, y = plot_tensorflow_log(log_file)\n",
        "plt.plot(x, y, '--', label='0.1 learning rate - validation')\n",
        "\n",
        "log_file = \"/content/drive/MyDrive/deep-learning/sgd/learning_rate_project/callback/0003/execution0/validation/events.out.tfevents.1648605434.f2bd2e92bee4.73.11.v2\"\n",
        "x, y = plot_tensorflow_log(log_file)\n",
        "plt.plot(x, y, '--', label='0.01 learning rate - validation')\n",
        "\n",
        "log_file = \"/content/drive/MyDrive/deep-learning/sgd/learning_rate_project/callback/0001/execution0/validation/events.out.tfevents.1648605358.f2bd2e92bee4.73.5.v2\"\n",
        "x, y = plot_tensorflow_log(log_file)\n",
        "plt.plot(x, y, '--', label='0.001 learning rate - validation')\n",
        "\n",
        "log_file = \"/content/drive/MyDrive/deep-learning/sgd/learning_rate_project/callback/0002/execution0/validation/events.out.tfevents.1648605396.f2bd2e92bee4.73.8.v2\"\n",
        "x, y = plot_tensorflow_log(log_file)\n",
        "plt.plot(x, y, '--', label='0.0001 learning rate - validation')\n",
        "\n",
        "\n",
        "plt.xlabel(\"Steps\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Training Progress - SGD\")\n",
        "plt.legend(loc='down right', frameon=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "a1WatOBNp8pN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initializer"
      ],
      "metadata": {
        "id": "wokLou4LxBYV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras import initializers\n",
        "\n",
        "def build_model(hp):\n",
        "  initializer = hp.Choice(\"initializer\", ['random_normal',\n",
        "                                          'random_uniform', \n",
        "                                          'zeros', \n",
        "                                          'ones'])\n",
        "  \n",
        "  model = keras.Sequential()\n",
        "  model.add(Dense(10, kernel_initializer=initializer, input_shape=(784,), activation='softmax'))\n",
        "\n",
        "  opt = keras.optimizers.SGD(learning_rate=0.001)\n",
        "  model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=[\"accuracy\"])\n",
        "  return model"
      ],
      "metadata": {
        "id": "q1yiCnCFxBYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_tuner as kt\n",
        "from tensorflow import keras\n",
        "\n",
        "tuner = kt.RandomSearch(\n",
        "    hypermodel=build_model,\n",
        "    objective=\"val_accuracy\",\n",
        "    max_trials=1000,\n",
        "    executions_per_trial=1,\n",
        "    overwrite=True,\n",
        "    directory=\"/content/drive/MyDrive/deep-learning/sgd/\",\n",
        "    project_name=\"initializer_project\"\n",
        ")\n",
        "\n",
        "tuner.search(X, \n",
        "             Y, \n",
        "             epochs=20, \n",
        "             validation_split=0.2, \n",
        "             callbacks=[tf.keras.callbacks.TensorBoard(\"/content/drive/MyDrive/deep-learning/sgd/initializer_project/callback\")],\n",
        "          \n",
        ")"
      ],
      "metadata": {
        "id": "yZGm60dwxBYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! rm -rf /content/drive/MyDrive/deep-learning/sgd/initializer_project/callback"
      ],
      "metadata": {
        "id": "gQz_z7OrxBYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir /content/drive/MyDrive/deep-learning/sgd/initializer_project/callback"
      ],
      "metadata": {
        "id": "yU0bYKojxBYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "log_file = \"/content/drive/MyDrive/deep-learning/sgd/initializer_project/callback/0000/execution0/train/events.out.tfevents.1648606551.f2bd2e92bee4.73.19.v2\"\n",
        "x, y = plot_tensorflow_log(log_file)\n",
        "plt.plot(x, y, label='ones - train')\n",
        "\n",
        "log_file = \"/content/drive/MyDrive/deep-learning/sgd/initializer_project/callback/0003/execution0/train/events.out.tfevents.1648606667.f2bd2e92bee4.73.28.v2\"\n",
        "x, y = plot_tensorflow_log(log_file)\n",
        "plt.plot(x, y, label='zeros - train')\n",
        "\n",
        "log_file = \"/content/drive/MyDrive/deep-learning/sgd/initializer_project/callback/0001/execution0/train/events.out.tfevents.1648606590.f2bd2e92bee4.73.22.v2\"\n",
        "x, y = plot_tensorflow_log(log_file)\n",
        "plt.plot(x, y, label='random normal - train')\n",
        "\n",
        "log_file = \"/content/drive/MyDrive/deep-learning/sgd/initializer_project/callback/0002/execution0/train/events.out.tfevents.1648606628.f2bd2e92bee4.73.25.v2\"\n",
        "x, y = plot_tensorflow_log(log_file)\n",
        "plt.plot(x, y, label='random uniform - train')\n",
        "\n",
        "\n",
        "log_file = \"/content/drive/MyDrive/deep-learning/sgd/initializer_project/callback/0000/execution0/validation/events.out.tfevents.1648606554.f2bd2e92bee4.73.20.v2\"\n",
        "x, y = plot_tensorflow_log(log_file)\n",
        "plt.plot(x, y, '--', label='ones - validation')\n",
        "\n",
        "log_file = \"/content/drive/MyDrive/deep-learning/sgd/initializer_project/callback/0003/execution0/validation/events.out.tfevents.1648606669.f2bd2e92bee4.73.29.v2\"\n",
        "x, y = plot_tensorflow_log(log_file)\n",
        "plt.plot(x, y, '--', label='zeros - validation')\n",
        "\n",
        "log_file = \"/content/drive/MyDrive/deep-learning/sgd/initializer_project/callback/0001/execution0/validation/events.out.tfevents.1648606592.f2bd2e92bee4.73.23.v2\"\n",
        "x, y = plot_tensorflow_log(log_file)\n",
        "plt.plot(x, y, '--', label='random normal - validation')\n",
        "\n",
        "log_file = \"/content/drive/MyDrive/deep-learning/sgd/initializer_project/callback/0001/execution0/validation/events.out.tfevents.1648606592.f2bd2e92bee4.73.23.v2\"\n",
        "x, y = plot_tensorflow_log(log_file)\n",
        "plt.plot(x, y, '--', label='random uniform - validation')\n",
        "\n",
        "plt.xlabel(\"Steps\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Training Progress - SGD\")\n",
        "plt.legend(loc='down right', frameon=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RcNimGB0xBYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Batch Size"
      ],
      "metadata": {
        "id": "at6FhAvw3cEo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyHyperModel(kt.HyperModel):\n",
        "    def build(self, hp):  \n",
        "      model = keras.Sequential()\n",
        "      model.add(Dense(10, kernel_initializer='uniform', input_shape=(784,), activation='softmax'))\n",
        "\n",
        "      opt = keras.optimizers.SGD(learning_rate=0.001)\n",
        "      model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=[\"accuracy\"])\n",
        "      return model\n",
        "\n",
        "    def fit(self, hp, model, *args, **kwargs):\n",
        "        return model.fit(\n",
        "            *args,\n",
        "            batch_size=hp.Choice(\"batch_size\", [8, 32, 128, 512, 2048]),\n",
        "            **kwargs,\n",
        "        )"
      ],
      "metadata": {
        "id": "CqJQXgdb3l_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_tuner as kt\n",
        "from tensorflow import keras\n",
        "\n",
        "tuner = kt.RandomSearch(\n",
        "    hypermodel=MyHyperModel(),\n",
        "    objective=\"val_accuracy\",\n",
        "    max_trials=1000,\n",
        "    executions_per_trial=1,\n",
        "    overwrite=True,\n",
        "    directory=\"/content/drive/MyDrive/deep-learning/sgd/\",\n",
        "    project_name=\"batch_size_project\"\n",
        ")\n",
        "\n",
        "tuner.search(X, \n",
        "             Y, \n",
        "             epochs=20, \n",
        "             validation_split=0.2, \n",
        "             callbacks=[tf.keras.callbacks.TensorBoard(\"/content/drive/MyDrive/deep-learning/sgd/batch_size_project/callback\")],\n",
        "          \n",
        ")"
      ],
      "metadata": {
        "id": "joaSRmC73cEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! rm -rf /content/drive/MyDrive/deep-learning/sgd/batch_size_project/callback"
      ],
      "metadata": {
        "id": "ePcvJM0n3cEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir /content/drive/MyDrive/deep-learning/sgd/batch_size_project/callback"
      ],
      "metadata": {
        "id": "gmN3BxV_3cEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "log_file = \"/content/drive/MyDrive/deep-learning/sgd/batch_size_project/callback/0003/execution0/train/events.out.tfevents.1648607170.f2bd2e92bee4.73.41.v2\"\n",
        "x, y = plot_tensorflow_log(log_file)\n",
        "plt.plot(x, y, label='8 batch size - train')\n",
        "\n",
        "log_file = \"/content/drive/MyDrive/deep-learning/sgd/batch_size_project/callback/0002/execution0/train/events.out.tfevents.1648607134.f2bd2e92bee4.73.38.v2\"\n",
        "x, y = plot_tensorflow_log(log_file)\n",
        "plt.plot(x, y, label='32 batch size - train')\n",
        "\n",
        "log_file = \"/content/drive/MyDrive/deep-learning/sgd/batch_size_project/callback/0005/execution0/train/events.out.tfevents.1648607312.f2bd2e92bee4.73.47.v2\"\n",
        "x, y = plot_tensorflow_log(log_file)\n",
        "plt.plot(x, y, label='128 batch size - train')\n",
        "\n",
        "log_file = \"/content/drive/MyDrive/deep-learning/sgd/batch_size_project/callback/0004/execution0/train/events.out.tfevents.1648607306.f2bd2e92bee4.73.44.v2\"\n",
        "x, y = plot_tensorflow_log(log_file)\n",
        "plt.plot(x, y, label='512 batch size - train')\n",
        "\n",
        "log_file = \"/content/drive/MyDrive/deep-learning/sgd/batch_size_project/callback/0001/execution0/train/events.out.tfevents.1648607130.f2bd2e92bee4.73.35.v2\"\n",
        "x, y = plot_tensorflow_log(log_file)\n",
        "plt.plot(x, y, label='2048 batch size - train')\n",
        "\n",
        "\n",
        "\n",
        "log_file = \"/content/drive/MyDrive/deep-learning/sgd/batch_size_project/callback/0003/execution0/validation/events.out.tfevents.1648607176.f2bd2e92bee4.73.42.v2\"\n",
        "x, y = plot_tensorflow_log(log_file)\n",
        "plt.plot(x, y, '--', label='8 batch size - validation')\n",
        "\n",
        "log_file = \"/content/drive/MyDrive/deep-learning/sgd/batch_size_project/callback/0002/execution0/validation/events.out.tfevents.1648607135.f2bd2e92bee4.73.39.v2\"\n",
        "x, y = plot_tensorflow_log(log_file)\n",
        "plt.plot(x, y, '--', label='32 batch size - validation')\n",
        "\n",
        "log_file = \"/content/drive/MyDrive/deep-learning/sgd/batch_size_project/callback/0005/execution0/validation/events.out.tfevents.1648607313.f2bd2e92bee4.73.48.v2\"\n",
        "x, y = plot_tensorflow_log(log_file)\n",
        "plt.plot(x, y, '--', label='128 batch size - validation')\n",
        "\n",
        "log_file = \"/content/drive/MyDrive/deep-learning/sgd/batch_size_project/callback/0004/execution0/validation/events.out.tfevents.1648607306.f2bd2e92bee4.73.45.v2\"\n",
        "x, y = plot_tensorflow_log(log_file)\n",
        "plt.plot(x, y, '--', label='512 batch size - validation')\n",
        "\n",
        "log_file = \"/content/drive/MyDrive/deep-learning/sgd/batch_size_project/callback/0001/execution0/validation/events.out.tfevents.1648607130.f2bd2e92bee4.73.36.v2\"\n",
        "x, y = plot_tensorflow_log(log_file)\n",
        "plt.plot(x, y, '--', label='2048 batch size - validation')\n",
        "\n",
        "\n",
        "plt.xlabel(\"Steps\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Training Progress - SGD\")\n",
        "plt.legend(loc='down right', frameon=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uZ57-bhT3cEv"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "DeepLearning-Assignment-2-File-Multiple-Optimizer.ipynb",
      "provenance": [],
      "mount_file_id": "1hI5F83Ud58U0WbVYF_96_tcWN4Ny2Uc9",
      "authorship_tag": "ABX9TyMqhvIEe9GaiyFCJYO1jWts",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}