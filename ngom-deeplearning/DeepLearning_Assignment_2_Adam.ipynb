{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/feknall/machinelearning-playground/blob/main/DeepLearning_Assignment_2_Adam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lawYx0ID-V3"
      },
      "source": [
        "### Installation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "XdaLy_Bnpl_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oskhbAFgEFsm"
      },
      "outputs": [],
      "source": [
        "! apt install ttf-mscorefonts-installer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nM4d-HdkEIWg"
      },
      "outputs": [],
      "source": [
        "! fc-cache -f"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xi85IbaVELGA"
      },
      "outputs": [],
      "source": [
        "! fc-match Arial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpqIoTADrl5X"
      },
      "source": [
        "### Loading MNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eNAE7b27qu9j"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "(x_train_both, y_train_both), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "print(x_train_both[x_train_both > 0])\n",
        "\n",
        "x_train_both = x_train_both.reshape((x_train_both.shape[0], -1)).astype('float32') / 255\n",
        "x_test = x_test.reshape((x_test.shape[0], -1)).astype('float32') / 255\n",
        "\n",
        "scaler = StandardScaler()\n",
        "x_train_both = scaler.fit_transform(x_train_both)\n",
        "x_test = scaler.transform(x_test)\n",
        "\n",
        "print(x_train_both[x_train_both > 0])\n",
        "\n",
        "x_train, x_validation, y_train, y_validation = train_test_split(x_train_both, y_train_both, test_size=0.2, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9-7Uo5pf7LO2"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "one_hot_encoder = OneHotEncoder()\n",
        "one_hot_encoder.fit(y_train.reshape(-1, 1))\n",
        "y_train_one_hot_encoded = one_hot_encoder.transform(y_train.reshape(-1, 1)).toarray()\n",
        "y_validation_hot_encoded = one_hot_encoder.transform(y_validation.reshape(-1, 1)).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RlR-6-fOws43"
      },
      "outputs": [],
      "source": [
        "print(f\"y_train: \\n{y_train.reshape(-1, 1)[:5]}\")\n",
        "print(f\"y_train_one_hot_encoded: \\n{y_train_one_hot_encoded[:5]}\")\n",
        "print(f\"y_validation_hot_encoded: \\n{y_validation_hot_encoded[:3]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "klEHrA7xv-HI"
      },
      "outputs": [],
      "source": [
        "print(x_train[0][:100])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Cipd6URlcXbg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBo1ySemXb8K"
      },
      "source": [
        "### SGD Classifier"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install tensorflow --upgrade"
      ],
      "metadata": {
        "id": "30W9CHDAlbwJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ci1V12SED_AI"
      },
      "outputs": [],
      "source": [
        "! pip install keras-tuner --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape((x_train.shape[0], -1)).astype('float32') / 255\n",
        "x_test = x_test.reshape((x_test.shape[0], -1)).astype('float32') / 255\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(x_train)\n",
        "x_train = scaler.transform(x_train)\n",
        "x_test = scaler.transform(x_test)"
      ],
      "metadata": {
        "id": "hK1KEzVGjQzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "one_hot_encoder = OneHotEncoder()\n",
        "one_hot_encoder.fit(y_train.reshape(-1, 1))\n",
        "y_train_one_hot_encoded = one_hot_encoder.transform(y_train.reshape(-1, 1)).toarray()"
      ],
      "metadata": {
        "id": "LlN_46y7jlKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXEqNMh8AkOP"
      },
      "source": [
        "### Keras Adam"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
        "import tensorflow as tf\n",
        "\n",
        "def plot_tensorflow_log(path):\n",
        "\n",
        "    # Loading too much data is slow...\n",
        "    tf_size_guidance = {\n",
        "        # 'compressedHistograms': 100,\n",
        "        # 'images': 0,\n",
        "        # 'scalars': 10000,\n",
        "        # 'histograms': 1000\n",
        "        'tensors': 200\n",
        "    }\n",
        "\n",
        "    event_acc = EventAccumulator(path, tf_size_guidance)\n",
        "    event_acc.Reload()\n",
        "\n",
        "    print(event_acc.Tags())\n",
        "\n",
        "    training_accuracies = event_acc.Tensors('epoch_accuracy')\n",
        "    tensor_np = tf.make_ndarray(training_accuracies[-1].tensor_proto)\n",
        "\n",
        "    print(tensor_np)\n",
        "\n",
        "    y = list()\n",
        "    x = list()\n",
        "    for i in range(len(training_accuracies)):\n",
        "        y.append(tf.make_ndarray(training_accuracies[i].tensor_proto))\n",
        "        x.append(i)\n",
        "\n",
        "    return x, y"
      ],
      "metadata": {
        "id": "WjAsZl1tqSju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "experiment_train_size = 20000\n",
        "X = x_train[:experiment_train_size]\n",
        "y = y_train_one_hot_encoded[:experiment_train_size]"
      ],
      "metadata": {
        "id": "k2luEiczs5VA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Learning Rate"
      ],
      "metadata": {
        "id": "jXXFq8WdwSxt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "def build_model(hp):\n",
        "  learning_rate = hp.Choice(\"learning_rate\", [0.1, 0.01, 0.001, 0.0001])\n",
        "\n",
        "  model = keras.Sequential()\n",
        "  model.add(Dense(10, kernel_initializer='uniform', input_shape=(784,), activation='softmax'))\n",
        "\n",
        "  opt = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "  model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=[\"accuracy\"])\n",
        "  return model"
      ],
      "metadata": {
        "id": "d7YCvgA_gaJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_tuner as kt\n",
        "from tensorflow import keras\n",
        "\n",
        "tuner = kt.RandomSearch(\n",
        "    hypermodel=build_model,\n",
        "    objective=\"val_accuracy\",\n",
        "    max_trials=1000,\n",
        "    executions_per_trial=1,\n",
        "    overwrite=True,\n",
        "    directory=\"/content/drive/MyDrive/deep-learning/adam/\",\n",
        "    project_name=\"learning_rate_project\"\n",
        ")\n",
        "\n",
        "tuner.search(X, \n",
        "             y, \n",
        "             epochs=20, \n",
        "             validation_split=0.2, \n",
        "             callbacks=[tf.keras.callbacks.TensorBoard(\"/content/drive/MyDrive/deep-learning/adam/learning_rate_project/callback\")],\n",
        "          \n",
        ")"
      ],
      "metadata": {
        "id": "uAa_kYTMhexG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! rm -rf /content/drive/MyDrive/deep-learning/adam/learning_rate_project"
      ],
      "metadata": {
        "id": "SvPcd3Jepc9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir /content/drive/MyDrive/deep-learning/adam/learning_rate_project/callback"
      ],
      "metadata": {
        "id": "ENAMzPbdpeYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "log_file = \"/content/drive/MyDrive/deep-learning/adam/learning_rate_project/callback/0000/execution0/train/events.out.tfevents.1649280351.6ba8d469f996.71.19.v2\"\n",
        "learing_rate_01_train_x, learing_rate_01_train_y = plot_tensorflow_log(log_file)\n",
        "log_file = \"/content/drive/MyDrive/deep-learning/adam/learning_rate_project/callback/0000/execution0/validation/events.out.tfevents.1649280353.6ba8d469f996.71.20.v2\"\n",
        "learing_rate_01_val_x, learing_rate_01_val_y = plot_tensorflow_log(log_file)\n",
        "\n",
        "log_file = \"/content/drive/MyDrive/deep-learning/adam/learning_rate_project/callback/0001/execution0/train/events.out.tfevents.1649280393.6ba8d469f996.71.22.v2\"\n",
        "learing_rate_00001_train_x, learing_rate_00001_train_y = plot_tensorflow_log(log_file)\n",
        "log_file = \"/content/drive/MyDrive/deep-learning/adam/learning_rate_project/callback/0001/execution0/validation/events.out.tfevents.1649280395.6ba8d469f996.71.23.v2\"\n",
        "learing_rate_00001_val_x, learing_rate_00001_val_y = plot_tensorflow_log(log_file)\n",
        "\n",
        "log_file = \"/content/drive/MyDrive/deep-learning/adam/learning_rate_project/callback/0002/execution0/train/events.out.tfevents.1649280431.6ba8d469f996.71.25.v2\"\n",
        "learing_rate_001_train_x, learing_rate_001_train_y = plot_tensorflow_log(log_file)\n",
        "log_file = \"/content/drive/MyDrive/deep-learning/adam/learning_rate_project/callback/0002/execution0/validation/events.out.tfevents.1649280433.6ba8d469f996.71.26.v2\"\n",
        "learing_rate_001_val_x, learing_rate_001_val_y = plot_tensorflow_log(log_file)\n",
        "\n",
        "log_file = \"/content/drive/MyDrive/deep-learning/adam/learning_rate_project/callback/0003/execution0/train/events.out.tfevents.1649280468.6ba8d469f996.71.28.v2\"\n",
        "learing_rate_0001_train_x, learing_rate_0001_train_y = plot_tensorflow_log(log_file)\n",
        "log_file = \"/content/drive/MyDrive/deep-learning/adam/learning_rate_project/callback/0003/execution0/validation/events.out.tfevents.1649280470.6ba8d469f996.71.29.v2\"\n",
        "learing_rate_0001_val_x, learing_rate_0001_val_y = plot_tensorflow_log(log_file)\n",
        "\n",
        "plt.plot(learing_rate_01_train_x, learing_rate_01_train_y, label='0.01 learning rate - train')\n",
        "plt.plot(learing_rate_00001_train_x, learing_rate_00001_train_y, label='0.0001 learning rate - train')\n",
        "plt.plot(learing_rate_001_train_x, learing_rate_001_train_y, label='0.01 learning rate - train')\n",
        "plt.plot(learing_rate_0001_train_x, learing_rate_0001_train_y, label='0.001 learning rate - train')\n",
        "\n",
        "plt.plot(learing_rate_01_val_x, learing_rate_01_val_y, '--', label='0.01 learning rate - train')\n",
        "plt.plot(learing_rate_00001_val_x, learing_rate_00001_val_y, '--', label='0.0001 learning rate - train')\n",
        "plt.plot(learing_rate_001_val_x, learing_rate_001_val_y, '--', label='0.01 learning rate - train')\n",
        "plt.plot(learing_rate_0001_val_x, learing_rate_0001_val_y, '--', label='0.001 learning rate - train')\n",
        "\n",
        "plt.xlabel(\"Steps\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Training Progress - Adam\")\n",
        "plt.legend(loc='down right', frameon=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "a1WatOBNp8pN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initializer"
      ],
      "metadata": {
        "id": "wokLou4LxBYV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras import initializers\n",
        "\n",
        "def build_model(hp):\n",
        "  initializer = hp.Choice(\"initializer\", ['random_normal',\n",
        "                                          'random_uniform', \n",
        "                                          'zeros', \n",
        "                                          'ones'])\n",
        "  \n",
        "  model = keras.Sequential()\n",
        "  model.add(Dense(10, kernel_initializer=initializer, input_shape=(784,), activation='softmax'))\n",
        "\n",
        "  opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "  model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=[\"accuracy\"])\n",
        "  return model"
      ],
      "metadata": {
        "id": "q1yiCnCFxBYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_tuner as kt\n",
        "from tensorflow import keras\n",
        "\n",
        "tuner = kt.RandomSearch(\n",
        "    hypermodel=build_model,\n",
        "    objective=\"val_accuracy\",\n",
        "    max_trials=1000,\n",
        "    executions_per_trial=1,\n",
        "    overwrite=True,\n",
        "    directory=\"/content/drive/MyDrive/deep-learning/\",\n",
        "    project_name=\"initializer_project\"\n",
        ")\n",
        "\n",
        "tuner.search(X, \n",
        "             y, \n",
        "             epochs=20, \n",
        "             validation_split=0.2, \n",
        "             callbacks=[tf.keras.callbacks.TensorBoard(\"/content/drive/MyDrive/deep-learning/initializer_project/callback\")],\n",
        "          \n",
        ")"
      ],
      "metadata": {
        "id": "yZGm60dwxBYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! rm -rf /content/drive/MyDrive/deep-learning/initializer_project/callback"
      ],
      "metadata": {
        "id": "gQz_z7OrxBYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir /content/drive/MyDrive/deep-learning/initializer_project/callback"
      ],
      "metadata": {
        "id": "yU0bYKojxBYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "log_file = \"/content/drive/MyDrive/deep-learning/initializer_project/callback/0002/execution0/train/events.out.tfevents.1648509262.baed5f330a88.60.63.v2\"\n",
        "x, y = plot_tensorflow_log(log_file)\n",
        "plt.plot(x, y, label='ones - train')\n",
        "\n",
        "log_file = \"/content/drive/MyDrive/deep-learning/initializer_project/callback/0001/execution0/train/events.out.tfevents.1648509237.baed5f330a88.60.60.v2\"\n",
        "x, y = plot_tensorflow_log(log_file)\n",
        "plt.plot(x, y, label='zeros - train')\n",
        "\n",
        "log_file = \"/content/drive/MyDrive/deep-learning/initializer_project/callback/0003/execution0/train/events.out.tfevents.1648509286.baed5f330a88.60.66.v2\"\n",
        "x, y = plot_tensorflow_log(log_file)\n",
        "plt.plot(x, y, label='random normal - train')\n",
        "\n",
        "log_file = \"/content/drive/MyDrive/deep-learning/initializer_project/callback/0000/execution0/train/events.out.tfevents.1648509209.baed5f330a88.60.57.v2\"\n",
        "x, y = plot_tensorflow_log(log_file)\n",
        "plt.plot(x, y, label='random uniform - train')\n",
        "\n",
        "\n",
        "log_file = \"/content/drive/MyDrive/deep-learning/initializer_project/callback/0002/execution0/validation/events.out.tfevents.1648509263.baed5f330a88.60.64.v2\"\n",
        "x, y = plot_tensorflow_log(log_file)\n",
        "plt.plot(x, y, '--', label='ones - validation')\n",
        "\n",
        "log_file = \"/content/drive/MyDrive/deep-learning/initializer_project/callback/0001/execution0/validation/events.out.tfevents.1648509238.baed5f330a88.60.61.v2\"\n",
        "x, y = plot_tensorflow_log(log_file)\n",
        "plt.plot(x, y, '--', label='zeros - validation')\n",
        "\n",
        "log_file = \"/content/drive/MyDrive/deep-learning/initializer_project/callback/0003/execution0/validation/events.out.tfevents.1648509288.baed5f330a88.60.67.v2\"\n",
        "x, y = plot_tensorflow_log(log_file)\n",
        "plt.plot(x, y, '--', label='random normal - validation')\n",
        "\n",
        "log_file = \"/content/drive/MyDrive/deep-learning/initializer_project/callback/0000/execution0/validation/events.out.tfevents.1648509213.baed5f330a88.60.58.v2\"\n",
        "x, y = plot_tensorflow_log(log_file)\n",
        "plt.plot(x, y, '--', label='random uniform - validation')\n",
        "\n",
        "plt.xlabel(\"Steps\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Training Progress - Adam\")\n",
        "plt.legend(loc='down right', frameon=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RcNimGB0xBYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Batch Size"
      ],
      "metadata": {
        "id": "at6FhAvw3cEo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyHyperModel(kt.HyperModel):\n",
        "    def build(self, hp):  \n",
        "      model = keras.Sequential()\n",
        "      model.add(Dense(10, kernel_initializer='uniform', input_shape=(784,), activation='softmax'))\n",
        "\n",
        "      opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "      model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=[\"accuracy\"])\n",
        "      return model\n",
        "\n",
        "    def fit(self, hp, model, *args, **kwargs):\n",
        "        return model.fit(\n",
        "            *args,\n",
        "            batch_size=hp.Choice(\"batch_size\", [8, 32, 128, 512, 2048]),\n",
        "            **kwargs,\n",
        "        )"
      ],
      "metadata": {
        "id": "CqJQXgdb3l_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_tuner as kt\n",
        "from tensorflow import keras\n",
        "\n",
        "tuner = kt.RandomSearch(\n",
        "    hypermodel=MyHyperModel(),\n",
        "    objective=\"val_accuracy\",\n",
        "    max_trials=1000,\n",
        "    executions_per_trial=1,\n",
        "    overwrite=True,\n",
        "    directory=\"/content/drive/MyDrive/deep-learning/\",\n",
        "    project_name=\"batch_size_project\"\n",
        ")\n",
        "\n",
        "tuner.search(X, \n",
        "             y, \n",
        "             epochs=20, \n",
        "             validation_split=0.2, \n",
        "             callbacks=[tf.keras.callbacks.TensorBoard(\"/content/drive/MyDrive/deep-learning/batch_size_project/callback\")],\n",
        "          \n",
        ")"
      ],
      "metadata": {
        "id": "joaSRmC73cEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! rm -rf /content/drive/MyDrive/deep-learning/batch_size_project/callback"
      ],
      "metadata": {
        "id": "ePcvJM0n3cEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir /content/drive/MyDrive/deep-learning/batch_size_project/callback"
      ],
      "metadata": {
        "id": "gmN3BxV_3cEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "log_file = \"/content/drive/MyDrive/deep-learning/batch_size_project/callback/0003/execution0/train/events.out.tfevents.1648510593.baed5f330a88.60.78.v2\"\n",
        "x, y = plot_tensorflow_log(log_file)\n",
        "plt.plot(x, y, label='8 batch size - train')\n",
        "\n",
        "log_file = \"/content/drive/MyDrive/deep-learning/batch_size_project/callback/0004/execution0/train/events.out.tfevents.1648510678.baed5f330a88.60.81.v2\"\n",
        "x, y = plot_tensorflow_log(log_file)\n",
        "plt.plot(x, y, label='32 batch size - train')\n",
        "\n",
        "log_file = \"/content/drive/MyDrive/deep-learning/batch_size_project/callback/0002/execution0/train/events.out.tfevents.1648510584.baed5f330a88.60.75.v2\"\n",
        "x, y = plot_tensorflow_log(log_file)\n",
        "plt.plot(x, y, label='128 batch size - train')\n",
        "\n",
        "log_file = \"/content/drive/MyDrive/deep-learning/batch_size_project/callback/0005/execution0/train/events.out.tfevents.1648510703.baed5f330a88.60.84.v2\"\n",
        "x, y = plot_tensorflow_log(log_file)\n",
        "plt.plot(x, y, label='512 batch size - train')\n",
        "\n",
        "log_file = \"/content/drive/MyDrive/deep-learning/batch_size_project/callback/0001/execution0/train/events.out.tfevents.1648510579.baed5f330a88.60.72.v2\"\n",
        "x, y = plot_tensorflow_log(log_file)\n",
        "plt.plot(x, y, label='2048 batch size - train')\n",
        "\n",
        "\n",
        "\n",
        "log_file = \"/content/drive/MyDrive/deep-learning/batch_size_project/callback/0003/execution0/validation/events.out.tfevents.1648510597.baed5f330a88.60.79.v2\"\n",
        "x, y = plot_tensorflow_log(log_file)\n",
        "plt.plot(x, y, '--', label='8 batch size - validation')\n",
        "\n",
        "log_file = \"/content/drive/MyDrive/deep-learning/batch_size_project/callback/0004/execution0/validation/events.out.tfevents.1648510680.baed5f330a88.60.82.v2\"\n",
        "x, y = plot_tensorflow_log(log_file)\n",
        "plt.plot(x, y, '--', label='32 batch size - validation')\n",
        "\n",
        "log_file = \"/content/drive/MyDrive/deep-learning/batch_size_project/callback/0002/execution0/validation/events.out.tfevents.1648510585.baed5f330a88.60.76.v2\"\n",
        "x, y = plot_tensorflow_log(log_file)\n",
        "plt.plot(x, y, '--', label='128 batch size - validation')\n",
        "\n",
        "log_file = \"/content/drive/MyDrive/deep-learning/batch_size_project/callback/0005/execution0/validation/events.out.tfevents.1648510703.baed5f330a88.60.85.v2\"\n",
        "x, y = plot_tensorflow_log(log_file)\n",
        "plt.plot(x, y, '--', label='512 batch size - validation')\n",
        "\n",
        "log_file = \"/content/drive/MyDrive/deep-learning/batch_size_project/callback/0001/execution0/validation/events.out.tfevents.1648510579.baed5f330a88.60.73.v2\"\n",
        "x, y = plot_tensorflow_log(log_file)\n",
        "plt.plot(x, y, '--', label='2048 batch size - validation')\n",
        "\n",
        "\n",
        "plt.xlabel(\"Steps\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Training Progress - Adam\")\n",
        "plt.legend(loc='down right', frameon=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uZ57-bhT3cEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Other"
      ],
      "metadata": {
        "id": "vMBJedOxwlcY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uLZ7BkgLouXf"
      },
      "outputs": [],
      "source": [
        "predicted = model.predict(x_test)\n",
        "print(predicted[0:10])\n",
        "\n",
        "predicted_decode = np.argmax(predicted, axis=1)\n",
        "print(predicted_decode)\n",
        "\n",
        "accuracy_score(y_test, predicted_decode)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Amf4GeyIAto-"
      },
      "source": [
        "### Keras Adadelta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4EazSrEU0B4c"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "adadelta_model = keras.Sequential()\n",
        "adadelta_model.add(layers.Dense(10, kernel_initializer='uniform', input_shape=(784,), activation='relu'))\n",
        "adadelta_model.add(layers.Activation('sigmoid'))\n",
        "\n",
        "opt = keras.optimizers.Adadelta(learning_rate=0.001)\n",
        "adadelta_model.compile(loss='categorical_crossentropy', optimizer=opt, )\n",
        "\n",
        "adadelta_model.fit(x_train, y_train_one_hot_encoded, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DRl78xKN0K0I"
      },
      "outputs": [],
      "source": [
        "predicted = adadelta_model.predict(x_test)\n",
        "predicted[0:10]\n",
        "\n",
        "predicted_decode = np.argmax(predicted, axis=1)\n",
        "\n",
        "accuracy_score(y_test, predicted_decode)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AR_gxBqLAxvT"
      },
      "source": [
        "### Keras SGD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ut3UYbA63aHE"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "adadelta_model = keras.Sequential()\n",
        "adadelta_model.add(layers.Dense(10, kernel_initializer='uniform', input_shape=(784,), activation='relu'))\n",
        "adadelta_model.add(layers.Activation('sigmoid'))\n",
        "\n",
        "opt = keras.optimizers.SGD(learning_rate=0.001)\n",
        "adadelta_model.compile(loss='categorical_crossentropy', optimizer=opt, )\n",
        "\n",
        "adadelta_model.fit(x_train, y_train_one_hot_encoded, epochs=10, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jLt1JpN93a-0"
      },
      "outputs": [],
      "source": [
        "predicted = adadelta_model.predict(x_test)\n",
        "predicted[0:10]\n",
        "\n",
        "predicted_decode = np.argmax(predicted, axis=1)\n",
        "\n",
        "accuracy_score(y_test, predicted_decode)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdyC8O3KA4yk"
      },
      "source": [
        "### Keras RMSprop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1163_7USA7dS"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "adadelta_model = keras.Sequential()\n",
        "adadelta_model.add(layers.Dense(10, kernel_initializer='uniform', input_shape=(784,), activation='relu'))\n",
        "adadelta_model.add(layers.Activation('sigmoid'))\n",
        "\n",
        "opt = keras.optimizers.RMSprop(learning_rate=0.001)\n",
        "adadelta_model.compile(loss='categorical_crossentropy', optimizer=opt, )\n",
        "\n",
        "adadelta_model.fit(x_train, y_train_one_hot_encoded, epochs=10, batch_size=32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cysi63dJBkmD"
      },
      "source": [
        "### L2 Regularization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zRdOGN0oBjrD"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "adadelta_model = keras.Sequential()\n",
        "adadelta_model.add(layers.Dense(10, kernel_initializer='uniform', input_shape=(784,), activation='relu', kernel_regularizer=regularizers.l2(1e-4)))\n",
        "adadelta_model.add(layers.Activation('sigmoid'))\n",
        "\n",
        "opt = keras.optimizers.RMSprop(learning_rate=0.001)\n",
        "adadelta_model.compile(loss='categorical_crossentropy', optimizer=opt, )\n",
        "\n",
        "adadelta_model.fit(x_train, y_train_one_hot_encoded, epochs=100, batch_size=32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLSsIvEtEFy9"
      },
      "source": [
        "### L1 Regularization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6bUUsQS_EIWN"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "adadelta_model = keras.Sequential()\n",
        "adadelta_model.add(layers.Dense(10, kernel_initializer='uniform', input_shape=(784,), activation='relu', kernel_regularizer=regularizers.l1(1e-4)))\n",
        "adadelta_model.add(layers.Activation('sigmoid'))\n",
        "\n",
        "opt = keras.optimizers.RMSprop(learning_rate=0.001)\n",
        "adadelta_model.compile(loss='categorical_crossentropy', optimizer=opt, )\n",
        "\n",
        "adadelta_model.fit(x_train, y_train_one_hot_encoded, epochs=10, batch_size=32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CeCaQGYiEhNu"
      },
      "source": [
        "### Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k8E3f-XQOXT8"
      },
      "outputs": [],
      "source": [
        "def random_flip_on_probability(image):\n",
        "    return tf.image.random_flip_up_down(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IBw2IESSEgzd"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "import random \n",
        "data_augmentation = tf.keras.Sequential([\n",
        "  # layers.RandomFlip(mode='horizontal'),\n",
        "  # layers.Lambda(random_flip_on_probability),\n",
        "  layers.RandomRotation(0.05),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QL5HuyXbMNbG"
      },
      "outputs": [],
      "source": [
        "x_train[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bwv3ZF20yK2T"
      },
      "outputs": [],
      "source": [
        "# from tensorflow.python.ops.numpy_ops import np_config\n",
        "# np_config.enable_numpy_behavior()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vyt1FDI0FU9I"
      },
      "outputs": [],
      "source": [
        "image = tf.cast(tf.expand_dims(x_train[1].reshape(28, 28, 1), 0), tf.float32)\n",
        "# image = tf.cast(tf.expand_dims(x_train[1].reshape(28, 28), 0), tf.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rLBze-0owyFY"
      },
      "outputs": [],
      "source": [
        "# fliped = tf.image.random_flip_up_down(image, seed=1)\n",
        "# plt.imshow(fliped[0].reshape(28, 28))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iu1ePlsXFgQC"
      },
      "outputs": [],
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(9):\n",
        "  augmented_image = data_augmentation(image)\n",
        "  ax = plt.subplot(3, 3, i + 1)\n",
        "  plt.imshow(augmented_image[0].reshape(28, 28))\n",
        "  plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hqf0w6mi2YtH"
      },
      "outputs": [],
      "source": [
        "# x_tensor = tf.cast(tf.expand_dims(x_train.reshape(-1, 28, 28, 1), 0), tf.float32)\n",
        "x_tensor = tf.cast(x_train.reshape(-1, 28, 28, 1), tf.float32)\n",
        "augmented_x = data_augmentation(x_tensor).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P5n2v0XM2lCG"
      },
      "outputs": [],
      "source": [
        "augmented_x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qo9Jx34Y3jVZ"
      },
      "outputs": [],
      "source": [
        "x_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sD7BhGUW32LT"
      },
      "outputs": [],
      "source": [
        "augmented_x_flat = augmented_x.reshape((augmented_x.shape[0], -1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g8twEoCa3-8s"
      },
      "outputs": [],
      "source": [
        "augmented_x_flat.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rhP6OpUN3GPY"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(9):\n",
        "  plt.subplot(3, 3, i + 1)\n",
        "  plt.imshow(augmented_x[i].reshape(28, 28))\n",
        "  plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ffsWvO04_tfS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "x_and_augmented = np.concatenate((augmented_x_flat, x_train))\n",
        "y_and_augmented = np.concatenate((y_train_one_hot_encoded, y_train_one_hot_encoded))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D-nshrUw_127"
      },
      "outputs": [],
      "source": [
        "x_and_augmented.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yNTDKPd7A6Cm"
      },
      "outputs": [],
      "source": [
        "y_and_augmented.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mpQkZsIL0XkC"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "adadelta_model = keras.Sequential()\n",
        "adadelta_model.add(layers.Dense(10, kernel_initializer='uniform', input_shape=(784,), activation='relu'))\n",
        "adadelta_model.add(layers.Activation('sigmoid'))\n",
        "\n",
        "opt = keras.optimizers.SGD(learning_rate=0.001)\n",
        "adadelta_model.compile(loss='categorical_crossentropy', optimizer=opt, )\n",
        "\n",
        "adadelta_model.fit(x_and_augmented, y_and_augmented, epochs=10, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MPZJHHNHBZe5"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "predicted = adadelta_model.predict(x_test)\n",
        "predicted[0:10]\n",
        "\n",
        "predicted_decode = np.argmax(predicted, axis=1)\n",
        "\n",
        "accuracy_score(y_test, predicted_decode)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGBQMr8sB8wE"
      },
      "source": [
        "### Dropout CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6TsEhykuB_-L"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, ZeroPadding2D\n",
        "\n",
        "\n",
        "def build_model(hp):\n",
        "  dropout = hp.Choice(\"dropout\", [0.1, 0.3, 0.5])\n",
        "\n",
        "  model = Sequential()\n",
        "\n",
        "  stride_size = 1\n",
        "  kernel_size = 3\n",
        "  pooling_size = 4\n",
        "\n",
        "  model.add(Conv2D(16, (kernel_size, kernel_size), strides=(stride_size, stride_size), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Conv2D(32, (kernel_size, kernel_size), strides=(stride_size, stride_size), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Conv2D(64, (kernel_size, kernel_size), strides=(stride_size, stride_size), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(16, activation='relu', kernel_initializer='he_uniform'))\n",
        "  model.add(Dense(16, activation='relu', kernel_initializer='he_uniform'))\n",
        "  model.add(Dense(16, activation='relu', kernel_initializer='he_uniform'))\n",
        "\n",
        "  model.add(Dropout(dropout))\n",
        "  model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "  model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n--DZdoYDaGQ"
      },
      "outputs": [],
      "source": [
        "import keras_tuner as kt\n",
        "\n",
        "tuner = kt.RandomSearch(\n",
        "    hypermodel=build_model,\n",
        "    objective=\"val_accuracy\",\n",
        "    max_trials=1000,\n",
        "    executions_per_trial=1,\n",
        "    overwrite=True,\n",
        "    directory=\"/content/drive/MyDrive/deep-learning/dropout_dir\",\n",
        "    project_name=\"dropout\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-u7NqaFzEiyg"
      },
      "outputs": [],
      "source": [
        "x_train = x_train.reshape(-1, 28, 28, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T6rpS_g6EtB7"
      },
      "outputs": [],
      "source": [
        "y_train_one_hot_encoded.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EKyBBOtODdNk"
      },
      "outputs": [],
      "source": [
        "experiment_train_size = 20000\n",
        "X = x_train[:experiment_train_size]\n",
        "y = y_train_one_hot_encoded[:experiment_train_size]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "egZ8FvMXDeeP"
      },
      "outputs": [],
      "source": [
        "tuner.search(X, \n",
        "             y, \n",
        "             epochs=20, \n",
        "             validation_split=0.2, \n",
        "             callbacks=[tf.keras.callbacks.TensorBoard(\"/content/drive/MyDrive/deep-learning/dropout_dir/callback\")],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JhPE7sf8Dgax"
      },
      "outputs": [],
      "source": [
        "tuner.results_summary(num_trials=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XrU7OGeiDikv"
      },
      "outputs": [],
      "source": [
        "! rm -rf /content/drive/MyDrive/ai-gras-1/pooling_size_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F8xqP7F0DkD8"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir /content/drive/MyDrive/ai-gras-1/dropout_dir/callback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35GBbVi5DojQ"
      },
      "outputs": [],
      "source": [
        "import tensorboard as tb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8IHZupkADpt1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "log_file = \"/content/drive/MyDrive/deep-learning/dropout_dir/callback/19b43427bf22fc3f3d2c8cb8ffeddc24/execution0/train/events.out.tfevents.1645936062.422681e7c282.70.11.v2\"\n",
        "dropout_1_train_x, dropout_1_train_y = plot_tensorflow_log(log_file)\n",
        "log_file = \"/content/drive/MyDrive/deep-learning/dropout_dir/callback/19b43427bf22fc3f3d2c8cb8ffeddc24/execution0/validation/events.out.tfevents.1645936077.422681e7c282.70.12.v2\"\n",
        "dropout_1_validation_x, dropout_1_validation_y = plot_tensorflow_log(log_file)\n",
        "\n",
        "log_file = \"/content/drive/MyDrive/deep-learning/dropout_dir/callback/dcf09ddea4ff8d89cb4591aa64ea6227/execution0/train/events.out.tfevents.1645936695.422681e7c282.70.17.v2\"\n",
        "dropout_3_train_x, dropout_3_train_y = plot_tensorflow_log(log_file)\n",
        "log_file = \"/content/drive/MyDrive/deep-learning/dropout_dir/callback/dcf09ddea4ff8d89cb4591aa64ea6227/execution0/validation/events.out.tfevents.1645936710.422681e7c282.70.18.v2\"\n",
        "dropout_3_validation_x, dropout_3_validation_y = plot_tensorflow_log(log_file)\n",
        "\n",
        "log_file = \"/content/drive/MyDrive/deep-learning/dropout_dir/callback/726c0d19a58adad10d9cdb9c404ac37f/execution0/train/events.out.tfevents.1645936372.422681e7c282.70.14.v2\"\n",
        "dropout_5_train_x, dropout_5_train_y = plot_tensorflow_log(log_file)\n",
        "log_file = \"/content/drive/MyDrive/deep-learning/dropout_dir/callback/726c0d19a58adad10d9cdb9c404ac37f/execution0/validation/events.out.tfevents.1645936386.422681e7c282.70.15.v2\"\n",
        "dropout_5_validation_x, dropout_5_validation_y = plot_tensorflow_log(log_file)\n",
        "\n",
        "plt.plot(dropout_1_train_x, dropout_1_train_y, label='0.1 dropout - train')\n",
        "plt.plot(dropout_3_train_x, dropout_3_train_y, label='0.3 dropout - train')\n",
        "plt.plot(dropout_5_train_x, dropout_5_train_y, label='0.5 dropout - train')\n",
        "\n",
        "plt.plot(dropout_1_validation_x, dropout_1_validation_y, '--', label='0.1 dropout - validation')\n",
        "plt.plot(dropout_3_validation_x, dropout_3_validation_y, '--', label='0.3 dropout - validation')\n",
        "plt.plot(dropout_5_validation_x, dropout_5_validation_y, '--', label='0.5 dropout - validation')\n",
        "\n",
        "plt.xlabel(\"Steps\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Training Progress\")\n",
        "plt.legend(loc='down right', frameon=True)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "DeepLearning-Assignment-2-Adam.ipynb",
      "provenance": [],
      "mount_file_id": "1o-gT9GBFBe8dRI7KVh6f46fDuVfLt6Mk",
      "authorship_tag": "ABX9TyMpLqNRTOZSc9a7Lu3tmgcS",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}