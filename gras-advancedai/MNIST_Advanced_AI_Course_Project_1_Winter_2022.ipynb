{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST-Advanced-AI-Course-Project-1-Winter-2022.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/feknall/machinelearning-playground/blob/main/MNIST_Advanced_AI_Course_Project_1_Winter_2022.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "DhDhaFdxFS6W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os"
      ],
      "metadata": {
        "id": "kfK_pdsKb6RF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
        "\n",
        "print('Train: X=%s, y=%s' % (train_X.shape, train_y.shape))\n",
        "print('Test: X=%s, y=%s' % (test_X.shape, test_y.shape))"
      ],
      "metadata": {
        "id": "xtLGzdx2YzBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ! rm -rf /content/drive"
      ],
      "metadata": {
        "id": "UHzxAVfM_WUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.flush_and_unmount()"
      ],
      "metadata": {
        "id": "bG2Vsk4-_GJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "8PyVlsjDSP1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(train_y, edgecolor='black', bins=np.arange(-0.5, 10))\n",
        "plt.hist(test_y, edgecolor='black', bins=np.arange(-0.5, 10))\n",
        "plt.subplots_adjust(top=1.4)\n",
        "plt.legend([\"training\", \"test\"], loc =\"top right\")\n",
        "\n",
        "plt.title('Distribution of Digits on Training and Test Dataset')\n",
        "plt.xlabel('Digit')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(np.arange(0, 10))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iCUGzxJ5Q8Fr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import random\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import DenseNet201\n",
        "\n",
        "import cv2\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "K0uIySNfcMcJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_y[5])"
      ],
      "metadata": {
        "id": "n1L8jYcQAq5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rows = 5\n",
        "columns = 10\n",
        "for digit in range(columns):\n",
        "\t\tselected = [index for index, value in enumerate(train_y) if value == digit][:rows]\n",
        "\t\tfor index, value in enumerate(selected):\n",
        "\t\t\tk = index * columns + digit + 1\n",
        "\t\t\tplt.subplot(rows, columns, k)\n",
        "\t\t\tplt.imshow(train_X[value], cmap=plt.get_cmap('gray'))\n",
        "\t\t\tplt.axis('off')\n",
        "\t\t\tplt.subplots_adjust(wspace=0.1, hspace=0.01)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oH0QG82FcJvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_X = train_X.reshape((-1, 28, 28, 1))\n",
        "test_X = test_X.reshape((-1, 28, 28, 1))"
      ],
      "metadata": {
        "id": "hUOFuugEcNig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "train_y = to_categorical(train_y)\n",
        "test_y = to_categorical(test_y)"
      ],
      "metadata": {
        "id": "C9eEWz6IcZaw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert from integers to floats\n",
        "train_X = train_X.astype('float32')\n",
        "test_X = test_X.astype('float32')\n",
        "\n",
        "# normalize to range 0-1\n",
        "train_X = train_X / 255.0\n",
        "test_X = test_X / 255.0\n",
        "\n",
        "print(train_X.shape)\n",
        "print(train_y.shape)\n",
        "\n",
        "print(test_X.shape)\n",
        "print(test_y.shape)"
      ],
      "metadata": {
        "id": "3Op7P3xBeBES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Base Model\n"
      ],
      "metadata": {
        "id": "5wuNa6AgEd6u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, AvgPool2D, BatchNormalization, Reshape,MaxPooling2D\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(16, activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(Dense(16, activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "O6UJkZCGEdRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import LearningRateScheduler\n",
        "\n",
        "experiment_train_size = 20000\n",
        "X = train_X[:experiment_train_size]\n",
        "y = train_y[:experiment_train_size]\n",
        "\n",
        "history = model.fit(X, y, validation_split=0.2, epochs=30, callbacks=[tf.keras.callbacks.TensorBoard(\"/content/drive/MyDrive/ai-gras-1/base-model/tensorboard\")])"
      ],
      "metadata": {
        "id": "PdLyb2LRE60O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save and Load"
      ],
      "metadata": {
        "id": "mIDoK3EHFeuM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save & Load History"
      ],
      "metadata": {
        "id": "NoFU3KRpVt6q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle "
      ],
      "metadata": {
        "id": "V9m0v2I1WCzH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/ai-gras-1/base-model/history.pkl', 'wb') as file_pi:\n",
        "        pickle.dump(history.history, file_pi)"
      ],
      "metadata": {
        "id": "IalGHAKdVEXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = pickle.load(open('/content/drive/MyDrive/ai-gras-1/base-model/history.pkl', \"rb\"))"
      ],
      "metadata": {
        "id": "ZJK0ZMcsVe0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save & Load Model"
      ],
      "metadata": {
        "id": "LCZx-AXWV17j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/ai-gras-1/base-model')"
      ],
      "metadata": {
        "id": "MFzmMGpPTUCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.load_model('/content/drive/MyDrive/ai-gras-1/base-model')"
      ],
      "metadata": {
        "id": "QhVNCUBcTh3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.summary())"
      ],
      "metadata": {
        "id": "TXi4pqL3UDRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plt.plot(history['accuracy'])\n",
        "# plt.plot(history['val_accuracy'])\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='down right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Wo2Twg_YGrgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reading Tensorboard Log Files"
      ],
      "metadata": {
        "id": "3NZ9nYv_9k0i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
        "import tensorflow as tf\n",
        "\n",
        "def plot_tensorflow_log(path):\n",
        "\n",
        "    # Loading too much data is slow...\n",
        "    tf_size_guidance = {\n",
        "        # 'compressedHistograms': 100,\n",
        "        # 'images': 0,\n",
        "        # 'scalars': 10000,\n",
        "        # 'histograms': 1000\n",
        "        'tensors': 200\n",
        "    }\n",
        "\n",
        "    event_acc = EventAccumulator(path, tf_size_guidance)\n",
        "    event_acc.Reload()\n",
        "\n",
        "    print(event_acc.Tags())\n",
        "\n",
        "    training_accuracies = event_acc.Tensors('epoch_accuracy')\n",
        "    tensor_np = tf.make_ndarray(training_accuracies[-1].tensor_proto)\n",
        "\n",
        "    print(tensor_np)\n",
        "\n",
        "    y = list()\n",
        "    x = list()\n",
        "    for i in range(len(training_accuracies)):\n",
        "        y.append(tf.make_ndarray(training_accuracies[i].tensor_proto))\n",
        "        x.append(i)\n",
        "\n",
        "    return x, y"
      ],
      "metadata": {
        "id": "qNKODJwH9iPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tunning"
      ],
      "metadata": {
        "id": "g2m1lIitFvmU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Number of Convolution Layers Tunning"
      ],
      "metadata": {
        "id": "uiq4HkrQCUh6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, ZeroPadding2D\n",
        "\n",
        "def build_model(hp):\n",
        "  conv_layers_count = hp.Int(\"conv_layers_count\", min_value=1, max_value=3, step=1)\n",
        "\n",
        "  model = Sequential()\n",
        "  if conv_layers_count == 1:\n",
        "    model.add(Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "  if conv_layers_count == 2:\n",
        "    model.add(Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "  if conv_layers_count == 3:\n",
        "    model.add(Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(16, activation='relu', kernel_initializer='he_uniform'))\n",
        "  model.add(Dense(16, activation='relu', kernel_initializer='he_uniform'))\n",
        "  model.add(Dropout(0.3))\n",
        "  model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "  model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "  return model"
      ],
      "metadata": {
        "id": "7eGIs9FeCSNh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_tuner as kt\n",
        "\n",
        "tuner = kt.RandomSearch(\n",
        "    hypermodel=build_model,\n",
        "    objective=\"val_accuracy\",\n",
        "    max_trials=1000,\n",
        "    executions_per_trial=1,\n",
        "    overwrite=True,\n",
        "    directory=\"/content/drive/MyDrive/ai-gras-1/conv_layers_count_dir\",\n",
        "    project_name=\"conv_layers_count\"\n",
        ")"
      ],
      "metadata": {
        "id": "sRrSN-05dNRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "experiment_train_size = 10000\n",
        "X = train_X[:experiment_train_size]\n",
        "y = train_y[:experiment_train_size]"
      ],
      "metadata": {
        "id": "aC1t4u_ydPDT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(X, \n",
        "             y, \n",
        "             epochs=20, \n",
        "             validation_split=0.2, \n",
        "             callbacks=[tf.keras.callbacks.TensorBoard(\"/content/drive/MyDrive/ai-gras-1/conv_layers_count_dir/callback\")],\n",
        ")"
      ],
      "metadata": {
        "id": "iAl-n-y_dQW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.results_summary(num_trials=3)"
      ],
      "metadata": {
        "id": "Qrk10YjHdXtF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! rm -rf /content/drive/MyDrive/ai-gras-1/conv_layers_count_dir"
      ],
      "metadata": {
        "id": "F__LBnei31-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kill 1652"
      ],
      "metadata": {
        "id": "XpNaIPWS4YMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search_space_summary(extended=True)"
      ],
      "metadata": {
        "id": "VvzrUxyJ6Q4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir /content/drive/MyDrive/ai-gras-1/conv_layers_count_dir/callback"
      ],
      "metadata": {
        "id": "yKZZbvFE4Q9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorboard as tb\n"
      ],
      "metadata": {
        "id": "-iiIbbTI8tqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "log_file = \"/content/drive/MyDrive/ai-gras-1/conv_layers_count_dir/callback/5f715b4a8e21afc1a5205749e67df494/execution0/train/events.out.tfevents.1645893894.6401f1a17419.84.30.v2\"\n",
        "conv_3_train_x, conv_3_train_y = plot_tensorflow_log(log_file)\n",
        "log_file = \"/content/drive/MyDrive/ai-gras-1/conv_layers_count_dir/callback/5f715b4a8e21afc1a5205749e67df494/execution0/validation/events.out.tfevents.1645893896.6401f1a17419.84.31.v2\"\n",
        "conv_3_validation_x, conv_3_validation_y = plot_tensorflow_log(log_file)\n",
        "\n",
        "\n",
        "log_file = \"/content/drive/MyDrive/ai-gras-1/conv_layers_count_dir/callback/61348a65887f0d4ce39edd0afe3e723e/execution0/train/events.out.tfevents.1645893860.6401f1a17419.84.27.v2\"\n",
        "conv_2_train_x, conv_2_train_y = plot_tensorflow_log(log_file)\n",
        "log_file = \"/content/drive/MyDrive/ai-gras-1/conv_layers_count_dir/callback/61348a65887f0d4ce39edd0afe3e723e/execution0/validation/events.out.tfevents.1645893862.6401f1a17419.84.28.v2\"\n",
        "conv_2_validation_x, conv_2_validation_y = plot_tensorflow_log(log_file)\n",
        "\n",
        "\n",
        "log_file = \"/content/drive/MyDrive/ai-gras-1/conv_layers_count_dir/callback/786acfe532a6fd3021ab0737d768ea37/execution0/train/events.out.tfevents.1645893819.6401f1a17419.84.24.v2\"\n",
        "conv_1_train_x, conv_1_train_y = plot_tensorflow_log(log_file)\n",
        "log_file = \"/content/drive/MyDrive/ai-gras-1/conv_layers_count_dir/callback/786acfe532a6fd3021ab0737d768ea37/execution0/validation/events.out.tfevents.1645893820.6401f1a17419.84.25.v2\"\n",
        "conv_1_validation_x, conv_1_validation_y = plot_tensorflow_log(log_file)\n",
        "\n",
        "plt.plot(conv_3_train_x, conv_3_train_y, label='3 convolution layer - train')\n",
        "plt.plot(conv_2_train_x, conv_2_train_y, label='2 convolution layer - train')\n",
        "plt.plot(conv_1_train_x, conv_1_train_y, label='1 convolution layer - train')\n",
        "\n",
        "plt.plot(conv_3_validation_x, conv_3_validation_y, '--', label='3 convolution layer - validation')\n",
        "plt.plot(conv_2_validation_x, conv_2_validation_y, '--', label='2 convolution layer - validation')\n",
        "plt.plot(conv_1_validation_x, conv_1_validation_y, '--', label='1 convolution layer - validation')\n",
        "\n",
        "plt.xlabel(\"Steps\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Training Progress\")\n",
        "plt.legend(loc='down right', frameon=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "niI59pqR-HiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Number of Hidden Layers Tunning"
      ],
      "metadata": {
        "id": "E3jqmd9Abjxx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, ZeroPadding2D\n",
        "\n",
        "def build_model(hp):\n",
        "  hidden_layers_count = hp.Int(\"hidden_layers_count\", min_value=1, max_value=3, step=1)\n",
        "  \n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  for i in range(hidden_layers_count):\n",
        "      model.add(Dense(16, activation='relu', kernel_initializer='he_uniform'))\n",
        "\n",
        "  model.add(Dropout(0.3))\n",
        "  model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "  model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "vC9IJKqrCSyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_tuner as kt\n",
        "\n",
        "tuner = kt.RandomSearch(\n",
        "    hypermodel=build_model,\n",
        "    objective=\"val_accuracy\",\n",
        "    max_trials=1000,\n",
        "    executions_per_trial=1,\n",
        "    overwrite=True,\n",
        "    directory=\"/content/drive/MyDrive/ai-gras-1/dens_layers_count_dir\",\n",
        "    project_name=\"dens_layers_count\"\n",
        ")"
      ],
      "metadata": {
        "id": "HoaXuQb_c-YY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "experiment_train_size = 20000\n",
        "X = train_X[:experiment_train_size]\n",
        "y = train_y[:experiment_train_size]"
      ],
      "metadata": {
        "id": "zXEbowGldLLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(X, \n",
        "             y, \n",
        "             epochs=20, \n",
        "             validation_split=0.2, \n",
        "             callbacks=[tf.keras.callbacks.TensorBoard(\"/content/drive/MyDrive/ai-gras-1/dens_layers_count_dir/callback\")],\n",
        ")"
      ],
      "metadata": {
        "id": "yvpXxTcUdEQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.results_summary(num_trials=3)"
      ],
      "metadata": {
        "id": "KNhDHZUdeWhA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! rm -rf /content/drive/MyDrive/ai-gras-1/dens_layers_count"
      ],
      "metadata": {
        "id": "jpSvvqPChYq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kill 1652"
      ],
      "metadata": {
        "id": "-JEuwlyAhYq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search_space_summary(extended=True)"
      ],
      "metadata": {
        "id": "-V7Ese_DhYq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir /content/drive/MyDrive/ai-gras-1/dens_layers_count/callback"
      ],
      "metadata": {
        "id": "N-raORhdhYq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorboard as tb"
      ],
      "metadata": {
        "id": "f6TcqXeshYq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "log_file = \"/content/drive/MyDrive/ai-gras-1/dens_layers_count/callback/310da671fde356bb178eb4a6ee01a7a6/execution0/train/events.out.tfevents.1645904681.6401f1a17419.84.55.v2\"\n",
        "dens_1_train_x, dens_1_train_y = plot_tensorflow_log(log_file)\n",
        "log_file = \"/content/drive/MyDrive/ai-gras-1/dens_layers_count/callback/310da671fde356bb178eb4a6ee01a7a6/execution0/validation/events.out.tfevents.1645904685.6401f1a17419.84.56.v2\"\n",
        "dens_1_validation_x, dens_1_validation_y = plot_tensorflow_log(log_file)\n",
        "\n",
        "log_file = \"/content/drive/MyDrive/ai-gras-1/dens_layers_count/callback/87e54330d7895fbd79b1aa7c66e48fe4/execution0/train/events.out.tfevents.1645904598.6401f1a17419.84.52.v2\"\n",
        "dens_2_train_x, dens_2_train_y = plot_tensorflow_log(log_file)\n",
        "log_file = \"/content/drive/MyDrive/ai-gras-1/dens_layers_count/callback/87e54330d7895fbd79b1aa7c66e48fe4/execution0/validation/events.out.tfevents.1645904602.6401f1a17419.84.53.v2\"\n",
        "dens_2_validation_x, dens_2_validation_y = plot_tensorflow_log(log_file)\n",
        "\n",
        "log_file = \"/content/drive/MyDrive/ai-gras-1/dens_layers_count/callback/90b0d45cc366dabad943cefe253ceb86/execution0/train/events.out.tfevents.1645904526.6401f1a17419.84.49.v2\"\n",
        "dens_3_train_x, dens_3_train_y = plot_tensorflow_log(log_file)\n",
        "log_file = \"/content/drive/MyDrive/ai-gras-1/dens_layers_count/callback/90b0d45cc366dabad943cefe253ceb86/execution0/validation/events.out.tfevents.1645904530.6401f1a17419.84.50.v2\"\n",
        "dens_3_validation_x, dens_3_validation_y = plot_tensorflow_log(log_file)\n",
        "\n",
        "plt.plot(dens_3_train_x, dens_3_train_y, label='3 dens layer - train')\n",
        "plt.plot(dens_2_train_x, dens_2_train_y, label='2 dens layer - train')\n",
        "plt.plot(dens_1_train_x, dens_1_train_y, label='1 dens layer - train')\n",
        "\n",
        "plt.plot(dens_3_validation_x, dens_3_validation_y, '--', label='3 dens layer - validation')\n",
        "plt.plot(dens_2_validation_x, dens_2_validation_y, '--', label='2 dens layer - validation')\n",
        "plt.plot(dens_1_validation_x, dens_1_validation_y, '--', label='1 dens layer - validation')\n",
        "\n",
        "plt.xlabel(\"Steps\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Training Progress\")\n",
        "plt.legend(loc='down right', frameon=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bPDeifz-hYq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Kernel Size Tunning"
      ],
      "metadata": {
        "id": "m9-dOeNEgS_w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, ZeroPadding2D\n",
        "\n",
        "def build_model(hp):\n",
        "  kernel_size = hp.Int(\"kernel_size\", min_value=2, max_value=4, step=1)\n",
        "  \n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Conv2D(16, (kernel_size, kernel_size), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Conv2D(32, (kernel_size, kernel_size), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Conv2D(64, (kernel_size, kernel_size), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(16, activation='relu', kernel_initializer='he_uniform'))\n",
        "  model.add(Dense(16, activation='relu', kernel_initializer='he_uniform'))\n",
        "  model.add(Dense(16, activation='relu', kernel_initializer='he_uniform'))\n",
        "\n",
        "  model.add(Dropout(0.3))\n",
        "  model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "  model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "oucAtR0BCS6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_tuner as kt\n",
        "\n",
        "tuner = kt.RandomSearch(\n",
        "    hypermodel=build_model,\n",
        "    objective=\"val_accuracy\",\n",
        "    max_trials=1000,\n",
        "    executions_per_trial=1,\n",
        "    overwrite=True,\n",
        "    directory=\"/content/drive/MyDrive/ai-gras-1/kernel_size_dir\",\n",
        "    project_name=\"kernel_size\"\n",
        ")"
      ],
      "metadata": {
        "id": "ccjh8ryXfH4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "experiment_train_size = 20000\n",
        "X = train_X[:experiment_train_size]\n",
        "y = train_y[:experiment_train_size]"
      ],
      "metadata": {
        "id": "avqJYQBkfIVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(X, \n",
        "             y, \n",
        "             epochs=20, \n",
        "             validation_split=0.2, \n",
        "             callbacks=[tf.keras.callbacks.TensorBoard(\"/content/drive/MyDrive/ai-gras-1/kernel_size_dir/callback\")],\n",
        ")"
      ],
      "metadata": {
        "id": "barmwYjLfIs_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.results_summary(num_trials=10)"
      ],
      "metadata": {
        "id": "DzAkiZZEfOdJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! rm -rf /content/drive/MyDrive/ai-gras-1/kernel_size_dir"
      ],
      "metadata": {
        "id": "yvxrAAwaoTce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! kill 5631"
      ],
      "metadata": {
        "id": "eOOctpmsoTcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir /content/drive/MyDrive/ai-gras-1/kernel_size_dir/callback"
      ],
      "metadata": {
        "id": "OJpWbDz4oTcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorboard as tb"
      ],
      "metadata": {
        "id": "ndLTSPqZoTcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "log_file = \"/content/drive/MyDrive/ai-gras-1/kernel_size_dir/callback/5b832d223d986ce101b771565403af91/execution0/train/events.out.tfevents.1645906151.6401f1a17419.84.73.v2\"\n",
        "kernel_4_train_x, kernel_4_train_y = plot_tensorflow_log(log_file)\n",
        "log_file = \"/content/drive/MyDrive/ai-gras-1/kernel_size_dir/callback/5b832d223d986ce101b771565403af91/execution0/validation/events.out.tfevents.1645906155.6401f1a17419.84.74.v2\"\n",
        "kernel_4_validation_x, kernel_4_validation_y = plot_tensorflow_log(log_file)\n",
        "\n",
        "log_file = \"/content/drive/MyDrive/ai-gras-1/kernel_size_dir/callback/c0099ed2d158eac53288dfc66ac6fa62/execution0/train/events.out.tfevents.1645906068.6401f1a17419.84.70.v2\"\n",
        "kernel_3_train_x, kernel_3_train_y = plot_tensorflow_log(log_file)\n",
        "log_file = \"/content/drive/MyDrive/ai-gras-1/kernel_size_dir/callback/c0099ed2d158eac53288dfc66ac6fa62/execution0/validation/events.out.tfevents.1645906072.6401f1a17419.84.71.v2\"\n",
        "kernel_3_validation_x, kernel_3_validation_y = plot_tensorflow_log(log_file)\n",
        "\n",
        "log_file = \"/content/drive/MyDrive/ai-gras-1/kernel_size_dir/callback/c463d84396ad1736a5f03ecfdbe09d62/execution0/train/events.out.tfevents.1645905992.6401f1a17419.84.67.v2\"\n",
        "kernel_2_train_x, kernel_2_train_y = plot_tensorflow_log(log_file)\n",
        "log_file = \"/content/drive/MyDrive/ai-gras-1/kernel_size_dir/callback/c463d84396ad1736a5f03ecfdbe09d62/execution0/validation/events.out.tfevents.1645905996.6401f1a17419.84.68.v2\"\n",
        "kernel_2_validation_x, kernel_2_validation_y = plot_tensorflow_log(log_file)\n",
        "\n",
        "\n",
        "plt.plot(kernel_4_train_x, kernel_4_train_y, label='(4, 4) kernel - train')\n",
        "plt.plot(kernel_3_train_x, kernel_3_train_y, label='(3, 3) kernel - train')\n",
        "plt.plot(kernel_2_train_x, kernel_2_train_y, label='(2, 2) kernel - train')\n",
        "\n",
        "plt.plot(kernel_4_validation_x, kernel_4_validation_y, '--', label='(4, 4) kernel - validation')\n",
        "plt.plot(kernel_3_validation_x, kernel_3_validation_y, '--', label='(3, 3) kernel - validation')\n",
        "plt.plot(kernel_2_validation_x, kernel_2_validation_y, '--', label='(2, 2) kernel - validation')\n",
        "\n",
        "plt.xlabel(\"Steps\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Training Progress\")\n",
        "plt.legend(loc='down right', frameon=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UBvdBnE5oTcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stride Tunning"
      ],
      "metadata": {
        "id": "pUZHC2vIhciR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, ZeroPadding2D\n",
        "\n",
        "def build_model(hp):\n",
        "  stride_size = hp.Int(\"stride_size\", min_value=1, max_value=3, step=1)\n",
        "\n",
        "  model = Sequential()\n",
        "\n",
        "  kernel_size = 3\n",
        "  model.add(Conv2D(16, (kernel_size, kernel_size), strides=(stride_size, stride_size), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Conv2D(32, (kernel_size, kernel_size), strides=(stride_size, stride_size), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  # When stride is larger than 1, we cannot have 3 conv layers.\n",
        "  # model.add(Conv2D(64, (kernel_size, kernel_size), strides=(stride_size, stride_size), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  # model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(16, activation='relu', kernel_initializer='he_uniform'))\n",
        "  model.add(Dense(16, activation='relu', kernel_initializer='he_uniform'))\n",
        "  model.add(Dense(16, activation='relu', kernel_initializer='he_uniform'))\n",
        "\n",
        "  model.add(Dropout(0.3))\n",
        "  model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "  model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "4iBrJmu0s2kK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_tuner as kt\n",
        "\n",
        "tuner = kt.RandomSearch(\n",
        "    hypermodel=build_model,\n",
        "    objective=\"val_accuracy\",\n",
        "    max_trials=1000,\n",
        "    executions_per_trial=1,\n",
        "    overwrite=True,\n",
        "    directory=\"/content/drive/MyDrive/ai-gras-1/stride_size_dir\",\n",
        "    project_name=\"stride_size\"\n",
        ")"
      ],
      "metadata": {
        "id": "9beuS1Y3hiYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "experiment_train_size = 20000\n",
        "X = train_X[:experiment_train_size]\n",
        "y = train_y[:experiment_train_size]"
      ],
      "metadata": {
        "id": "j0dY9Uhihj2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(X, \n",
        "             y, \n",
        "             epochs=20, \n",
        "             validation_split=0.2, \n",
        "             callbacks=[tf.keras.callbacks.TensorBoard(\"/content/drive/MyDrive/ai-gras-1/stride_size_dir/callback\")],\n",
        ")"
      ],
      "metadata": {
        "id": "d79YJCFbhmB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.results_summary(num_trials=10)"
      ],
      "metadata": {
        "id": "Yoj2VPL7hoRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! rm -rf /content/drive/MyDrive/ai-gras-1/kernel_size_dir"
      ],
      "metadata": {
        "id": "0TPsqQRqs9j-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kill 5631"
      ],
      "metadata": {
        "id": "wnXu0XXos9j-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir /content/drive/MyDrive/ai-gras-1/stride_size_dir/callback"
      ],
      "metadata": {
        "id": "Ei-1RQE7s9j-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorboard as tb"
      ],
      "metadata": {
        "id": "4w0-vMyUs9j-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "log_file = \"/content/drive/MyDrive/ai-gras-1/stride_size_dir/callback/992088f8a5eead3968655d87084349ee/execution0/train/events.out.tfevents.1645907110.6401f1a17419.84.82.v2\"\n",
        "stride_1_train_x, stride_1_train_y = plot_tensorflow_log(log_file)\n",
        "log_file = \"/content/drive/MyDrive/ai-gras-1/stride_size_dir/callback/992088f8a5eead3968655d87084349ee/execution0/validation/events.out.tfevents.1645907114.6401f1a17419.84.83.v2\"\n",
        "stride_1_validation_x, stride_1_validation_y = plot_tensorflow_log(log_file)\n",
        "\n",
        "log_file = \"/content/drive/MyDrive/ai-gras-1/stride_size_dir/callback/30171d7697c15faa760ec54e3452a379/execution0/train/events.out.tfevents.1645906971.6401f1a17419.84.76.v2\"\n",
        "stride_3_train_x, stride_3_train_y = plot_tensorflow_log(log_file)\n",
        "log_file = \"/content/drive/MyDrive/ai-gras-1/stride_size_dir/callback/30171d7697c15faa760ec54e3452a379/execution0/validation/events.out.tfevents.1645906974.6401f1a17419.84.77.v2\"\n",
        "stride_3_validation_x, stride_3_validation_y = plot_tensorflow_log(log_file)\n",
        "\n",
        "log_file = \"/content/drive/MyDrive/ai-gras-1/stride_size_dir/callback/30df4f775d475e507d2d249868357de1/execution0/train/events.out.tfevents.1645907027.6401f1a17419.84.79.v2\"\n",
        "stride_2_train_x, stride_2_train_y = plot_tensorflow_log(log_file)\n",
        "log_file = \"/content/drive/MyDrive/ai-gras-1/stride_size_dir/callback/30df4f775d475e507d2d249868357de1/execution0/validation/events.out.tfevents.1645907030.6401f1a17419.84.80.v2\"\n",
        "stride_2_validation_x, stride_2_validation_y = plot_tensorflow_log(log_file)\n",
        "\n",
        "plt.plot(stride_3_train_x, stride_3_train_y, label='(3, 3) stride - train')\n",
        "plt.plot(stride_2_train_x, stride_2_train_y, label='(2, 2) stride - train')\n",
        "plt.plot(stride_1_train_x, stride_1_train_y, label='(1, 1) stride - train')\n",
        "\n",
        "plt.plot(stride_3_validation_x, stride_3_validation_y, '--', label='(3, 3) stride - validation')\n",
        "plt.plot(stride_2_validation_x, stride_2_validation_y, '--', label='(2, 2) stride - validation')\n",
        "plt.plot(stride_1_validation_x, stride_1_validation_y, '--', label='(1, 1) stride - validation')\n",
        "\n",
        "plt.xlabel(\"Steps\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Training Progress\")\n",
        "plt.legend(loc='down right', frameon=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BvnW8GZps9j-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pooling Size Tunning"
      ],
      "metadata": {
        "id": "dyGMT6FDkOGg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, ZeroPadding2D\n",
        "\n",
        "\n",
        "def build_model(hp):\n",
        "  pooling_size = hp.Int(\"pooling_size\", min_value=2, max_value=4, step=1)\n",
        "\n",
        "  model = Sequential()\n",
        "\n",
        "  stride_size = 1\n",
        "  kernel_size = 3\n",
        "  model.add(Conv2D(16, (kernel_size, kernel_size), strides=(stride_size, stride_size), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Conv2D(32, (kernel_size, kernel_size), strides=(stride_size, stride_size), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Conv2D(64, (kernel_size, kernel_size), strides=(stride_size, stride_size), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(16, activation='relu', kernel_initializer='he_uniform'))\n",
        "  model.add(Dense(16, activation='relu', kernel_initializer='he_uniform'))\n",
        "  model.add(Dense(16, activation='relu', kernel_initializer='he_uniform'))\n",
        "\n",
        "  model.add(Dropout(0.3))\n",
        "  model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "  model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "-noXB9yVkMht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_tuner as kt\n",
        "\n",
        "tuner = kt.RandomSearch(\n",
        "    hypermodel=build_model,\n",
        "    objective=\"val_accuracy\",\n",
        "    max_trials=1000,\n",
        "    executions_per_trial=1,\n",
        "    overwrite=True,\n",
        "    directory=\"/content/drive/MyDrive/ai-gras-1/pooling_size_dir\",\n",
        "    project_name=\"pooling_size\"\n",
        ")"
      ],
      "metadata": {
        "id": "ibEjw1Z4kNYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "experiment_train_size = 20000\n",
        "X = train_X[:experiment_train_size]\n",
        "y = train_y[:experiment_train_size]"
      ],
      "metadata": {
        "id": "JX21WyjKkNXA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(X, \n",
        "             y, \n",
        "             epochs=20, \n",
        "             validation_split=0.2, \n",
        "             callbacks=[tf.keras.callbacks.TensorBoard(\"/content/drive/MyDrive/ai-gras-1/pooling_size_dir/callback\")],\n",
        ")"
      ],
      "metadata": {
        "id": "y8or0325kNSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.results_summary(num_trials=10)"
      ],
      "metadata": {
        "id": "S7JWdjQWkNHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! rm -rf /content/drive/MyDrive/ai-gras-1/pooling_size_dir"
      ],
      "metadata": {
        "id": "oH332dIb0Dlg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir /content/drive/MyDrive/ai-gras-1/pooling_size_dir/callback"
      ],
      "metadata": {
        "id": "OuAwPP3S7I9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorboard as tb"
      ],
      "metadata": {
        "id": "vh7xqd327I9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "log_file = \"/content/drive/MyDrive/ai-gras-1/pooling_size_dir/callback/cb57392469e65be1bf093b69a08c238c/execution0/train/events.out.tfevents.1645909670.8a122e665f20.71.25.v2\"\n",
        "pooling_4_train_x, pooling_4_train_y = plot_tensorflow_log(log_file)\n",
        "log_file = \"/content/drive/MyDrive/ai-gras-1/pooling_size_dir/callback/cb57392469e65be1bf093b69a08c238c/execution0/validation/events.out.tfevents.1645909686.8a122e665f20.71.26.v2\"\n",
        "pooling_4_validation_x, pooling_4_validation_y = plot_tensorflow_log(log_file)\n",
        "\n",
        "log_file = \"/content/drive/MyDrive/ai-gras-1/pooling_size_dir/callback/ec8eae30827f57bb4d061789faf9a927/execution0/train/events.out.tfevents.1645908904.8a122e665f20.71.19.v2\"\n",
        "pooling_3_train_x, pooling_3_train_y = plot_tensorflow_log(log_file)\n",
        "log_file = \"/content/drive/MyDrive/ai-gras-1/pooling_size_dir/callback/ec8eae30827f57bb4d061789faf9a927/execution0/validation/events.out.tfevents.1645908920.8a122e665f20.71.20.v2\"\n",
        "pooling_3_validation_x, pooling_3_validation_y = plot_tensorflow_log(log_file)\n",
        "\n",
        "log_file = \"/content/drive/MyDrive/ai-gras-1/pooling_size_dir/callback/e85e6847b52552a3beb6e2c34d936a37/execution0/train/events.out.tfevents.1645909287.8a122e665f20.71.22.v2\"\n",
        "pooling_2_train_x, pooling_2_train_y = plot_tensorflow_log(log_file)\n",
        "log_file = \"/content/drive/MyDrive/ai-gras-1/pooling_size_dir/callback/e85e6847b52552a3beb6e2c34d936a37/execution0/validation/events.out.tfevents.1645909304.8a122e665f20.71.23.v2\"\n",
        "pooling_2_validation_x, pooling_2_validation_y = plot_tensorflow_log(log_file)\n",
        "\n",
        "plt.plot(pooling_4_train_x, pooling_4_train_y, label='(4, 4) max pooling - train')\n",
        "plt.plot(pooling_3_train_x, pooling_3_train_y, label='(3, 3) max pooling - train')\n",
        "plt.plot(pooling_2_train_x, pooling_2_train_y, label='(2, 2) max pooling - train')\n",
        "\n",
        "plt.plot(pooling_4_validation_x, pooling_4_validation_y, '--', label='(4, 4) max pooling - validation')\n",
        "plt.plot(pooling_3_validation_x, pooling_3_validation_y, '--', label='(3, 3) max pooling - validation')\n",
        "plt.plot(pooling_2_validation_x, pooling_2_validation_y, '--', label='(2, 2) max pooling - validation')\n",
        "\n",
        "plt.xlabel(\"Steps\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Training Progress\")\n",
        "plt.legend(loc='down right', frameon=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_QKPTmLT7I9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras"
      ],
      "metadata": {
        "id": "WhW8FcZMjrWK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_hp = tuner.get_best_hyperparameters()[0]\n",
        "best_hp"
      ],
      "metadata": {
        "id": "D7od4USBfNPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_models = tuner.get_best_models(num_models=1)"
      ],
      "metadata": {
        "id": "aC_8oYgdgdr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import visualkeras\n",
        "from PIL import ImageFont\n",
        "\n",
        "font = ImageFont.truetype(\"/content/font/Roboto-Regular.ttf\", 12)\n",
        "visualkeras.layered_view(best_models[0], to_file='output.png', legend=True, font=font).show()"
      ],
      "metadata": {
        "id": "e4tDQfQ43chT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_models[0].get_config()"
      ],
      "metadata": {
        "id": "7npxwXHQg4l1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_models[0].summary()"
      ],
      "metadata": {
        "id": "UHaDwGQxglrm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "8fTTlCJ9iZR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! ls /content/tf"
      ],
      "metadata": {
        "id": "m66aIvsRkHCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir /content/drive/MyDrive/ai-gras-1/conv_layers_count"
      ],
      "metadata": {
        "id": "kX1yVqmbicVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dropout Tunning"
      ],
      "metadata": {
        "id": "Np3msT4wVX0g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, ZeroPadding2D\n",
        "\n",
        "\n",
        "def build_model(hp):\n",
        "  dropout = hp.Choice(\"dropout\", [0.1, 0.3, 0.5])\n",
        "\n",
        "  model = Sequential()\n",
        "\n",
        "  stride_size = 1\n",
        "  kernel_size = 3\n",
        "  pooling_size = 4\n",
        "\n",
        "  model.add(Conv2D(16, (kernel_size, kernel_size), strides=(stride_size, stride_size), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Conv2D(32, (kernel_size, kernel_size), strides=(stride_size, stride_size), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Conv2D(64, (kernel_size, kernel_size), strides=(stride_size, stride_size), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(16, activation='relu', kernel_initializer='he_uniform'))\n",
        "  model.add(Dense(16, activation='relu', kernel_initializer='he_uniform'))\n",
        "  model.add(Dense(16, activation='relu', kernel_initializer='he_uniform'))\n",
        "\n",
        "  model.add(Dropout(dropout))\n",
        "  model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "  model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "D5uixdmdVX0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_tuner as kt\n",
        "\n",
        "tuner = kt.RandomSearch(\n",
        "    hypermodel=build_model,\n",
        "    objective=\"val_accuracy\",\n",
        "    max_trials=1000,\n",
        "    executions_per_trial=1,\n",
        "    overwrite=True,\n",
        "    directory=\"/content/drive/MyDrive/ai-gras-1/dropout_dir\",\n",
        "    project_name=\"dropout\"\n",
        ")"
      ],
      "metadata": {
        "id": "JugdNoiUVX0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "experiment_train_size = 20000\n",
        "X = train_X[:experiment_train_size]\n",
        "y = train_y[:experiment_train_size]"
      ],
      "metadata": {
        "id": "Bx17lxHGVX0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(X, \n",
        "             y, \n",
        "             epochs=20, \n",
        "             validation_split=0.2, \n",
        "             callbacks=[tf.keras.callbacks.TensorBoard(\"/content/drive/MyDrive/ai-gras-1/dropout_dir/callback\")],\n",
        ")"
      ],
      "metadata": {
        "id": "Uh5TPzcFVX0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.results_summary(num_trials=10)"
      ],
      "metadata": {
        "id": "OIsra6YKVX0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! rm -rf /content/drive/MyDrive/ai-gras-1/pooling_size_dir"
      ],
      "metadata": {
        "id": "--feBVJ_VX0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir /content/drive/MyDrive/ai-gras-1/dropout_dir/callback"
      ],
      "metadata": {
        "id": "7i07LlWkVX0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorboard as tb"
      ],
      "metadata": {
        "id": "GZMRaXr7VX0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "log_file = \"/content/drive/MyDrive/ai-gras-1/dropout_dir/callback/19b43427bf22fc3f3d2c8cb8ffeddc24/execution0/train/events.out.tfevents.1645936062.422681e7c282.70.11.v2\"\n",
        "dropout_1_train_x, dropout_1_train_y = plot_tensorflow_log(log_file)\n",
        "log_file = \"/content/drive/MyDrive/ai-gras-1/dropout_dir/callback/19b43427bf22fc3f3d2c8cb8ffeddc24/execution0/validation/events.out.tfevents.1645936077.422681e7c282.70.12.v2\"\n",
        "dropout_1_validation_x, dropout_1_validation_y = plot_tensorflow_log(log_file)\n",
        "\n",
        "log_file = \"/content/drive/MyDrive/ai-gras-1/dropout_dir/callback/dcf09ddea4ff8d89cb4591aa64ea6227/execution0/train/events.out.tfevents.1645936695.422681e7c282.70.17.v2\"\n",
        "dropout_3_train_x, dropout_3_train_y = plot_tensorflow_log(log_file)\n",
        "log_file = \"/content/drive/MyDrive/ai-gras-1/dropout_dir/callback/dcf09ddea4ff8d89cb4591aa64ea6227/execution0/validation/events.out.tfevents.1645936710.422681e7c282.70.18.v2\"\n",
        "dropout_3_validation_x, dropout_3_validation_y = plot_tensorflow_log(log_file)\n",
        "\n",
        "log_file = \"/content/drive/MyDrive/ai-gras-1/dropout_dir/callback/726c0d19a58adad10d9cdb9c404ac37f/execution0/train/events.out.tfevents.1645936372.422681e7c282.70.14.v2\"\n",
        "dropout_5_train_x, dropout_5_train_y = plot_tensorflow_log(log_file)\n",
        "log_file = \"/content/drive/MyDrive/ai-gras-1/dropout_dir/callback/726c0d19a58adad10d9cdb9c404ac37f/execution0/validation/events.out.tfevents.1645936386.422681e7c282.70.15.v2\"\n",
        "dropout_5_validation_x, dropout_5_validation_y = plot_tensorflow_log(log_file)\n",
        "\n",
        "plt.plot(dropout_1_train_x, dropout_1_train_y, label='0.1 dropout - train')\n",
        "plt.plot(dropout_3_train_x, dropout_3_train_y, label='0.3 dropout - train')\n",
        "plt.plot(dropout_5_train_x, dropout_5_train_y, label='0.5 dropout - train')\n",
        "\n",
        "plt.plot(dropout_1_validation_x, dropout_1_validation_y, '--', label='0.1 dropout - validation')\n",
        "plt.plot(dropout_3_validation_x, dropout_3_validation_y, '--', label='0.3 dropout - validation')\n",
        "plt.plot(dropout_5_validation_x, dropout_5_validation_y, '--', label='0.5 dropout - validation')\n",
        "\n",
        "plt.xlabel(\"Steps\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Training Progress\")\n",
        "plt.legend(loc='down right', frameon=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sE88YMAVVX0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Others"
      ],
      "metadata": {
        "id": "301XnZ1wVqsx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras"
      ],
      "metadata": {
        "id": "PVOQq_evVX0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_hp = tuner.get_best_hyperparameters()[0]\n",
        "best_hp"
      ],
      "metadata": {
        "id": "DqRawyPdVX0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_models = tuner.get_best_models(num_models=1)"
      ],
      "metadata": {
        "id": "mLjbqMe-VX0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import visualkeras\n",
        "from PIL import ImageFont\n",
        "\n",
        "font = ImageFont.truetype(\"/content/font/Roboto-Regular.ttf\", 12)\n",
        "visualkeras.layered_view(best_models[0], to_file='output.png', legend=True, font=font).show()"
      ],
      "metadata": {
        "id": "Eq-Sx6AlVX0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_models[0].get_config()"
      ],
      "metadata": {
        "id": "nCJcovL9VX0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_models[0].summary()"
      ],
      "metadata": {
        "id": "GFN53_4SVX0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensorboard Loading"
      ],
      "metadata": {
        "id": "8RRhvk_5fwTf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "z7Q6J3ngVX0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! ls /content/tf"
      ],
      "metadata": {
        "id": "FPTu6TJ3VX0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir /content/drive/MyDrive/ai-gras-1/conv_layers_count"
      ],
      "metadata": {
        "id": "olxFdotJVX0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final Model"
      ],
      "metadata": {
        "id": "7bSHDVD0F0Nf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final Model"
      ],
      "metadata": {
        "id": "o436doI4BWPC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, AvgPool2D, BatchNormalization, Reshape,MaxPooling2D\n",
        "\n",
        "def base_model():\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(16, activation='relu', kernel_initializer='he_uniform'))\n",
        "  model.add(Dense(16, activation='relu', kernel_initializer='he_uniform'))\n",
        "  model.add(Dropout(0.1))\n",
        "  model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "  model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "SaWwYEwGBrJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, ZeroPadding2D\n",
        "\n",
        "\n",
        "def final_model():\n",
        "  model = Sequential()\n",
        "\n",
        "  stride_size = 1\n",
        "  kernel_size = 3\n",
        "  pooling_size = 4\n",
        "\n",
        "  model.add(Conv2D(16, (kernel_size, kernel_size), strides=(stride_size, stride_size), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(MaxPooling2D((pooling_size, pooling_size)))\n",
        "  model.add(Conv2D(32, (kernel_size, kernel_size), strides=(stride_size, stride_size), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(MaxPooling2D((pooling_size, pooling_size)))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(16, activation='relu', kernel_initializer='he_uniform'))\n",
        "  model.add(Dense(16, activation='relu', kernel_initializer='he_uniform'))\n",
        "\n",
        "  model.add(Dropout(0.1))\n",
        "  model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "  model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "ghf1OarCBYca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import LearningRateScheduler\n",
        "\n",
        "experiment_train_size = 60000\n",
        "X = train_X[:experiment_train_size]\n",
        "y = train_y[:experiment_train_size]"
      ],
      "metadata": {
        "id": "H53B2vcHBrJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_base = base_model()\n",
        "history_base = model_base.fit(X, y, validation_split=0.2, epochs=100, callbacks=[tf.keras.callbacks.TensorBoard(\"/content/drive/MyDrive/ai-gras-1/base-model-100-2/tensorboard\")])\n",
        "model_base.save('/content/drive/MyDrive/ai-gras-1/base-model-100-2/save')"
      ],
      "metadata": {
        "id": "oxQ1e5v1CyxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_final = final_model()\n",
        "history_final = model_final.fit(X, y, validation_split=0.2, epochs=50, callbacks=[tf.keras.callbacks.TensorBoard(\"/content/drive/MyDrive/ai-gras-1/final-model-100-5/tensorboard\")])\n",
        "model_final.save('/content/drive/MyDrive/ai-gras-1/final-model-100-5/save')"
      ],
      "metadata": {
        "id": "M5jcM7W2C1MQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! rm -rf /content/drive/MyDrive/ai-gras-1/final-model\n",
        "! rm -rf /content/drive/MyDrive/ai-gras-1/base-model"
      ],
      "metadata": {
        "id": "UOUeIvtvmr8w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_final.summary()"
      ],
      "metadata": {
        "id": "9zPVvawKHiWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(2,1, figsize=(18, 10))\n",
        "ax[0].plot(history_final.history['loss'], color='b', label=\"Training loss\")\n",
        "ax[0].plot(history_final.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\n",
        "legend = ax[0].legend(loc='best', shadow=True)\n",
        "\n",
        "ax[1].plot(history_final.history['accuracy'], color='b', label=\"Training accuracy\")\n",
        "ax[1].plot(history_final.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
        "legend = ax[1].legend(loc='best', shadow=True)"
      ],
      "metadata": {
        "id": "X91DkD3YIJub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir /content/drive/MyDrive/ai-gras-1/base-model-100/tensorboard"
      ],
      "metadata": {
        "id": "SYJWGBSxlzTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir /content/drive/MyDrive/ai-gras-1/final-model-100-2/tensorboard"
      ],
      "metadata": {
        "id": "cng7YmVjmGH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorboard as tb"
      ],
      "metadata": {
        "id": "9Hl6054smGH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "log_file = \"/content/drive/MyDrive/ai-gras-1/base-model-100/tensorboard/train/events.out.tfevents.1645922209.8a122e665f20.71.33.v2\"\n",
        "base_x_train, base_y_train = plot_tensorflow_log(log_file)\n",
        "log_file = \"/content/drive/MyDrive/ai-gras-1/base-model-100/tensorboard/validation/events.out.tfevents.1645922251.8a122e665f20.71.34.v2\"\n",
        "base_x_validation, base_y_validation = plot_tensorflow_log(log_file)\n",
        "\n",
        "log_file = \"/content/drive/MyDrive/ai-gras-1/final-model-100/tensorboard/train/events.out.tfevents.1645926707.8a122e665f20.71.37.v2\"\n",
        "final_x_train, final_y_train = plot_tensorflow_log(log_file)\n",
        "log_file = \"/content/drive/MyDrive/ai-gras-1/final-model-100/tensorboard/validation/events.out.tfevents.1645926764.8a122e665f20.71.38.v2\"\n",
        "final_x_validation, final_y_validation = plot_tensorflow_log(log_file)\n",
        "\n",
        "plt.plot(base_x_train, base_y_train, label='base model - train')\n",
        "plt.plot(final_x_train, final_y_train, label='final model - train')\n",
        "\n",
        "plt.plot(base_x_validation, base_y_validation, '--', label='base model - validation')\n",
        "plt.plot(final_x_validation, final_y_validation, '--', label='final model - validation')\n",
        "\n",
        "plt.xlabel(\"Steps\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Training Progress\")\n",
        "plt.legend(loc='down right', frameon=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Iem6ePYtmGH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score, acc = base_model.evaluate(test_X, text_y)\n",
        "print('Test score:', score)\n",
        "print('Test accuracy:', acc)"
      ],
      "metadata": {
        "id": "SOgwNEnQRUPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final Model Test Accuracy"
      ],
      "metadata": {
        "id": "do7iBZmpFyvY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.load_model('/content/drive/MyDrive/ai-gras-1/save')"
      ],
      "metadata": {
        "id": "lq5lXLcHFx32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.evaluate(test_X, test_y)"
      ],
      "metadata": {
        "id": "Gnh7f1qTGGuq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# System Spec"
      ],
      "metadata": {
        "id": "u2IascYSukfZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! python --version"
      ],
      "metadata": {
        "id": "ypyGeIxXuEXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! python -c 'import keras; print(keras.__version__)'"
      ],
      "metadata": {
        "id": "akLIULQeuPlZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! python -c 'import tensorflow as tf; print(tf.__version__)'"
      ],
      "metadata": {
        "id": "AZVAvt_ruSCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! nvidia-smi -L"
      ],
      "metadata": {
        "id": "q-jbHk_TUwHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cat /proc/cpuinfo"
      ],
      "metadata": {
        "id": "jitt0uDvu1xP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installation"
      ],
      "metadata": {
        "id": "3T7EEPRSzzT3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visual Keras"
      ],
      "metadata": {
        "id": "OqkTg4ONEURl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install git+https://github.com/paulgavrikov/visualkeras"
      ],
      "metadata": {
        "id": "BT1EEu37zvtb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Keras Tuner"
      ],
      "metadata": {
        "id": "xKAwc-8BEWWm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install keras-tuner --upgrade"
      ],
      "metadata": {
        "id": "G8mO9jtjtQF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fonts"
      ],
      "metadata": {
        "id": "Swp4a0fm5SqR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! apt install ttf-mscorefonts-installer"
      ],
      "metadata": {
        "id": "eqJ4Bodc5Kry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! fc-cache -f"
      ],
      "metadata": {
        "id": "dRV6JVG15PQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! fc-match Arial"
      ],
      "metadata": {
        "id": "aGbCtU035foh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trash"
      ],
      "metadata": {
        "id": "5k16RKNit-dS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "#Initalize Image Data Generator \n",
        "imageDataGenerator= ImageDataGenerator(\n",
        "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        zoom_range = 0.1, # Randomly zoom image \n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=False,  # randomly flip images\n",
        "        vertical_flip=False,validation_split=0.2\n",
        ")\n",
        "\n",
        "# trainData = imageDataGenerator.flow(trainX, trainY, batch_size=64)\n",
        "# valData = imageDataGenerator.flow(testX, testX, batch_size=64)\n",
        " # creating train data for our model\n",
        "trainData = imageDataGenerator.flow(train_X,\n",
        "                                    train_y,        \n",
        "                                    batch_size=64,\n",
        "                                    subset='training',\n",
        "                                                    # shuffle=True,\n",
        "                                                    \n",
        "                                                   )\n",
        "# creating validate data for our model\n",
        "valData = imageDataGenerator.flow(train_X,\n",
        "                                  train_y,\n",
        "                                  batch_size=64,\n",
        "                                  subset='validation'\n",
        "                                                    # shuffle=True,\n",
        "                                                    )\n",
        "# # creating test data for our model\n",
        "testData = imageDataGenerator.flow(train_X,\n",
        "                                   train_y,         \n",
        "                                   batch_size=1,    \n",
        "                                   shuffle=True,\n",
        "                                   seed=42)\n"
      ],
      "metadata": {
        "id": "1_cynj6ke3Iy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_batch, y_batch = trainData.next()\n",
        "\n",
        "plt.imshow(x_batch[:1].reshape(28, 28), cmap='gray')\n",
        "plt.show()\n",
        "# for j in range(64):\n"
      ],
      "metadata": {
        "id": "1BUuIGH9NRKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_X.shape"
      ],
      "metadata": {
        "id": "kezqIq8SQrGr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_X = np.empty(shape=(28, 28, 1))\n",
        "for x_batch, y_batch in trainData:\n",
        " np.append(new_X, x_batch)"
      ],
      "metadata": {
        "id": "Yl4aAX6jQTkt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = trainData"
      ],
      "metadata": {
        "id": "9LYuQ0IJLAnQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(X)"
      ],
      "metadata": {
        "id": "Gf6g9oZkLDiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(trainData)"
      ],
      "metadata": {
        "id": "PRTwETP0KSw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = [0] *15"
      ],
      "metadata": {
        "id": "fJGXzFNbUR7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, AvgPool2D, BatchNormalization, Reshape,MaxPooling2D\n",
        "\n",
        "model[0] = Sequential()\n",
        "model[0].add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model[0].add(MaxPooling2D((2, 2)))\n",
        "model[0].add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model[0].add(MaxPooling2D((2, 2)))\n",
        "model[0].add(Flatten())\n",
        "model[0].add(Dense(32, activation='relu', kernel_initializer='he_uniform'))\n",
        "model[0].add(Dropout(0.3))\n",
        "model[0].add(Dense(10, activation='softmax'))\n",
        "\n",
        "# example output part of the model\n",
        "# model.add(Flatten())\n",
        "# model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "# model.add(Dense(10, activation='softmax'))\n",
        "model[0].compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "_iFaaioPF20f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    os.mkdir(\"tmp\")\n",
        "except:\n",
        "    print(\"Directory /tmp already exists\")\n",
        "\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(\"tmp/multi_class_weights_1\", \n",
        "                                                monitor='val_loss', \n",
        "                                                verbose=1, \n",
        "                                                save_best_only=False,\n",
        "                                                save_weights_only=True, \n",
        "                                                period=1)"
      ],
      "metadata": {
        "id": "P0z83I_CWPNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train our model\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "\n",
        "# history = model.fit(trainData, epochs = 20, validation_data =valData, steps_per_epoch=32, callbacks=[LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x, verbose=0)], verbose=0)\n",
        "# history = model.fit(trainData, epochs = 20, validation_data =valData, steps_per_epoch=32, callbacks=[checkpoint], verbose=0)\n",
        "# dense_net_transfer_history = model.fit(trainData, validation_data=valData, epochs=40, steps_per_epoch=32, callbacks=[checkpoint])\n",
        "history = model[0].fit(trainData, validation_data=valData, epochs=10, steps_per_epoch=32, callbacks=[checkpoint])"
      ],
      "metadata": {
        "id": "rhPf_kFANgFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = model[0].evaluate(testData, verbose=0)\n",
        "# print('%.3f' % (acc * 100.0))\n",
        "print(acc)"
      ],
      "metadata": {
        "id": "M4rs2NSnUzyt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ino nemidoonam chiye\n",
        "print(\"CNN: Epochs={0:d}, Train accuracy={1:.5f}, Validation accuracy={2:.5f}\".format(epochs,max(history.history['acc']),max(history.history['val_acc']) ))\n"
      ],
      "metadata": {
        "id": "MASXGGlTOp8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot\n",
        "# test harness for evaluating models on the cifar10 dataset\n",
        "import sys\n",
        "def summarize_diagnostics(history):\n",
        "\t# plot loss\n",
        "\tpyplot.subplot(211)\n",
        "\tpyplot.title('Cross Entropy Loss')\n",
        "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
        "\t# plot accuracy\n",
        "\tpyplot.subplot(212)\n",
        "\tpyplot.title('Classification Accuracy')\n",
        "\tpyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
        "\tpyplot.show()\n",
        "  # save plot to file\n",
        "\t# filename = sys.argv[0].split('/')[-1]\n",
        "\t# pyplot.savefig(filename + '_plot.png')\n",
        "\t# pyplot.close()"
      ],
      "metadata": {
        "id": "UwxFZi82UB8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summarize_diagnostics(history)"
      ],
      "metadata": {
        "id": "9iZdozUAUDH2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}